
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Topic Modelling &#8212; My sample book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Welcome to your Jupyter Book" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">My sample book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Topic Modelling
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/topic-modelling.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Ftopic-modelling.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/topic-modelling.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Topic Modelling
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#install-import-library">
     Install &amp; Import Library
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#crawling-data">
   Crawling Data
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-scrapy-project">
     Create Scrapy Project
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#crawling-link-pta">
     Crawling Link PTA
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#crawling-detail-pta">
     Crawling Detail PTA
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preprocessing-data">
   Preprocessing Data
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#read-dataset">
     Read Dataset
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cleaning-tokenizing">
     Cleaning &amp; Tokenizing
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stopwords">
     Stopwords
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stopwords-dictionary">
       Stopwords Dictionary
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stemming">
     Stemming
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stemming-dictionary">
       Stemming Dictionary
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#term-frequency-inverse-document-frequency">
     Term Frequency - Inverse Document Frequency
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     TOPIC MODELLING
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#latent-semantic-analysis-lsa">
       Latent Semantic Analysis(LSA)
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#singular-value-decomposition-svd">
         Singular Value Decomposition(SVD)
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#term-penting-setiap-topik">
       10 term penting setiap topik
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#latent-dirichlet-allocation-lda">
       Latent Dirichlet Allocation (LDA)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       10 term penting setiap topik
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#term-penting-dengan-wordcloud">
       50 term penting dengan wordcloud
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Topic Modelling</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Topic Modelling
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#install-import-library">
     Install &amp; Import Library
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#crawling-data">
   Crawling Data
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-scrapy-project">
     Create Scrapy Project
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#crawling-link-pta">
     Crawling Link PTA
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#crawling-detail-pta">
     Crawling Detail PTA
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preprocessing-data">
   Preprocessing Data
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#read-dataset">
     Read Dataset
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cleaning-tokenizing">
     Cleaning &amp; Tokenizing
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stopwords">
     Stopwords
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stopwords-dictionary">
       Stopwords Dictionary
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stemming">
     Stemming
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stemming-dictionary">
       Stemming Dictionary
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#term-frequency-inverse-document-frequency">
     Term Frequency - Inverse Document Frequency
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     TOPIC MODELLING
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#latent-semantic-analysis-lsa">
       Latent Semantic Analysis(LSA)
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#singular-value-decomposition-svd">
         Singular Value Decomposition(SVD)
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#term-penting-setiap-topik">
       10 term penting setiap topik
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#latent-dirichlet-allocation-lda">
       Latent Dirichlet Allocation (LDA)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       10 term penting setiap topik
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#term-penting-dengan-wordcloud">
       50 term penting dengan wordcloud
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="topic-modelling">
<h1>Topic Modelling<a class="headerlink" href="#topic-modelling" title="Permalink to this headline">#</a></h1>
<section id="install-import-library">
<h2>Install &amp; Import Library<a class="headerlink" href="#install-import-library" title="Permalink to this headline">#</a></h2>
<p>Jika anda ingin menjalankan notebook secara offline seperti Jupyter Notebook, pastikan perangkat anda sudah terinstall library yang dibutuhkan. Jika anda ingin menjalankan notebook secara online seperti Google Colaboratory, pastikan notebook tersebut sudah terinstall library yang dibutuhkan. Library yang dibutuhkan dalam proyek ini, yaitu:</p>
<ul class="simple">
<li><p>Scrapy</p></li>
<li><p>OS</p></li>
<li><p>Regex</p></li>
<li><p>Pandas</p></li>
<li><p>NLTK</p></li>
<li><p>Sklearn</p></li>
<li><p>Sastrawi</p></li>
<li><p>Wordcloud</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import Library</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">regex</span> <span class="k">as</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">TruncatedSVD</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="kn">from</span> <span class="nn">Sastrawi.Stemmer.StemmerFactory</span> <span class="kn">import</span> <span class="n">StemmerFactory</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">LatentDirichletAllocation</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
<span class="kn">from</span> <span class="nn">wordcloud</span> <span class="kn">import</span> <span class="n">WordCloud</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1"># Install NLTK Corpus</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;stopwords&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package stopwords to
[nltk_data]     C:\Users\Acer\AppData\Roaming\nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package punkt to
[nltk_data]     C:\Users\Acer\AppData\Roaming\nltk_data...
[nltk_data]   Package punkt is already up-to-date!
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="crawling-data">
<h1>Crawling Data<a class="headerlink" href="#crawling-data" title="Permalink to this headline">#</a></h1>
<section id="create-scrapy-project">
<h2>Create Scrapy Project<a class="headerlink" href="#create-scrapy-project" title="Permalink to this headline">#</a></h2>
<p>Pada bagian ini digunakan untuk membuat proyek library Scrapy dan memindah posisi direktori. Proyek library Scrapy diberi nama crawlproject. Posisi direktori dipindah ke crawlproject/crawlproject/spiders</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Membuat proyek library Scrapy</span>
<span class="o">!</span>scrapy startproject crawlproject
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Error: scrapy.cfg already exists in D:\Kuliah\Semester 6\Penambangan dan Pencarian Web\jupyter-book\PPW\crawlproject
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Melihat posisi direktori saat ini</span>
<span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;D:\\Kuliah\\Semester 6\\Penambangan dan Pencarian Web\\jupyter-book\\PPW&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mengubah posisi direktori saat ini ke crawlproject/crawlproject/spiders</span>
<span class="c1"># Fungsinya agar bisa menjalankan file proyek library Scrapy</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">&#39;crawlproject/crawlproject/spiders&#39;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;D:\\Kuliah\\Semester 6\\Penambangan dan Pencarian Web\\jupyter-book\\PPW\\crawlproject\\crawlproject\\spiders&#39;
</pre></div>
</div>
</div>
</div>
</section>
<section id="crawling-link-pta">
<h2>Crawling Link PTA<a class="headerlink" href="#crawling-link-pta" title="Permalink to this headline">#</a></h2>
<p>Pada bagian ini digunakan untuk membuat dan menjalankan program python. Program tersebut digunakan untuk melakukan <em>crawling</em> 40 link tugas akhir teknik informatika. Untuk melakukan <em>crawling</em> menggunakan library scrapy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> -a link.py
<span class="c1"># Membuat file link.py</span>
<span class="c1"># File link.py digunakan untuk crawling link tugas akhir</span>
<span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;quotes&quot;</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;https://pta.trunojoyo.ac.id/c_search/byprod/10/1&#39;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">9</span><span class="p">):</span>
            <span class="n">tambah</span> <span class="o">=</span> <span class="s1">&#39;https://pta.trunojoyo.ac.id/c_search/byprod/10/&#39;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">start_urls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tambah</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">start_urls</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">&#39;link&#39;</span><span class="p">:</span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;#content_journal &gt; ul &gt; li:nth-child(&#39;</span> <span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">+</span> <span class="s1">&#39;) &gt; div:nth-child(3) &gt; a::attr(href)&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
            <span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Appending to link.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menjalankan file link.py untuk melakukan proses crawling link tugas akhir</span>
<span class="c1"># Hasil akan disimpan dalam file link.csv</span>
<span class="c1"># File link.csv digunakan untuk melakukan crawling detail tugas akhir</span>
<span class="o">!</span>scrapy runspider link.py -o link.csv
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Python310\lib\site-packages\scrapy\spiderloader.py:37: UserWarning: There are several spiders with the same name:

  QuotesSpider named &#39;quotes&#39; (in crawlproject.spiders.detail)

  QuotesSpider named &#39;quotes&#39; (in crawlproject.spiders.link)

  This can cause unexpected behavior.
  warnings.warn(
2022-06-29 22:20:51 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: crawlproject)
2022-06-29 22:20:51 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021), cryptography 36.0.1, Platform Windows-10-10.0.19044-SP0
2022-06-29 22:20:51 [scrapy.crawler] INFO: Overridden settings:
{&#39;BOT_NAME&#39;: &#39;crawlproject&#39;,
 &#39;NEWSPIDER_MODULE&#39;: &#39;crawlproject.spiders&#39;,
 &#39;ROBOTSTXT_OBEY&#39;: True,
 &#39;SPIDER_LOADER_WARN_ONLY&#39;: True,
 &#39;SPIDER_MODULES&#39;: [&#39;crawlproject.spiders&#39;]}
2022-06-29 22:20:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2022-06-29 22:20:51 [scrapy.extensions.telnet] INFO: Telnet Password: 0c1babab7d282c3c
2022-06-29 22:20:51 [scrapy.middleware] INFO: Enabled extensions:
[&#39;scrapy.extensions.corestats.CoreStats&#39;,
 &#39;scrapy.extensions.telnet.TelnetConsole&#39;,
 &#39;scrapy.extensions.feedexport.FeedExporter&#39;,
 &#39;scrapy.extensions.logstats.LogStats&#39;]
2022-06-29 22:20:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
[&#39;scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.retry.RetryMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.redirect.RedirectMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.cookies.CookiesMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.stats.DownloaderStats&#39;]
2022-06-29 22:20:51 [scrapy.middleware] INFO: Enabled spider middlewares:
[&#39;scrapy.spidermiddlewares.httperror.HttpErrorMiddleware&#39;,
 &#39;scrapy.spidermiddlewares.offsite.OffsiteMiddleware&#39;,
 &#39;scrapy.spidermiddlewares.referer.RefererMiddleware&#39;,
 &#39;scrapy.spidermiddlewares.urllength.UrlLengthMiddleware&#39;,
 &#39;scrapy.spidermiddlewares.depth.DepthMiddleware&#39;]
2022-06-29 22:20:51 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-06-29 22:20:51 [scrapy.core.engine] INFO: Spider opened
2022-06-29 22:20:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-06-29 22:20:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-06-29 22:20:52 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/robots.txt&gt; (referer: None)
2022-06-29 22:20:53 [filelock] DEBUG: Attempting to acquire lock 1867958981232 on C:\Users\Acer\.cache\python-tldextract\3.10.1.final__Python310__a9c9a9__tldextract-3.2.0\publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
2022-06-29 22:20:53 [filelock] DEBUG: Lock 1867958981232 acquired on C:\Users\Acer\.cache\python-tldextract\3.10.1.final__Python310__a9c9a9__tldextract-3.2.0\publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
2022-06-29 22:20:53 [filelock] DEBUG: Attempting to acquire lock 1867959307568 on C:\Users\Acer\.cache\python-tldextract\3.10.1.final__Python310__a9c9a9__tldextract-3.2.0\urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
2022-06-29 22:20:53 [filelock] DEBUG: Lock 1867959307568 acquired on C:\Users\Acer\.cache\python-tldextract\3.10.1.final__Python310__a9c9a9__tldextract-3.2.0\urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
2022-06-29 22:20:53 [filelock] DEBUG: Attempting to release lock 1867959307568 on C:\Users\Acer\.cache\python-tldextract\3.10.1.final__Python310__a9c9a9__tldextract-3.2.0\urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
2022-06-29 22:20:53 [filelock] DEBUG: Lock 1867959307568 released on C:\Users\Acer\.cache\python-tldextract\3.10.1.final__Python310__a9c9a9__tldextract-3.2.0\urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
2022-06-29 22:20:53 [filelock] DEBUG: Attempting to release lock 1867958981232 on C:\Users\Acer\.cache\python-tldextract\3.10.1.final__Python310__a9c9a9__tldextract-3.2.0\publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
2022-06-29 22:20:53 [filelock] DEBUG: Lock 1867958981232 released on C:\Users\Acer\.cache\python-tldextract\3.10.1.final__Python310__a9c9a9__tldextract-3.2.0\publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
2022-06-29 22:20:53 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/c_search/byprod/10/1&gt; (referer: None)
2022-06-29 22:20:53 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/c_search/byprod/10/2&gt; (referer: None)
2022-06-29 22:20:53 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/c_search/byprod/10/3&gt; (referer: None)
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/1&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/040411100468&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/1&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/040411100476&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/1&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/040411100480&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/1&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100070&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/1&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/080411100115&#39;]}
2022-06-29 22:20:53 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/c_search/byprod/10/6&gt; (referer: None)
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/2&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100007&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/2&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100126&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/2&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100109&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/2&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/080411100083&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/2&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100092&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/3&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100120&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/3&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100143&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/3&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100037&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/3&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100079&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/3&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100050&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/6&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/080411100086&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/6&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/080411100052&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/6&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/060411100818&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/6&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/080411100125&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/6&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/080411100029&#39;]}
2022-06-29 22:20:53 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/c_search/byprod/10/7&gt; (referer: None)
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/7&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/060411100755&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/7&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/080411100102&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/7&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/050411100662&#39;]}
2022-06-29 22:20:53 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/c_search/byprod/10/4&gt; (referer: None)
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/7&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/080411100014&#39;]}
2022-06-29 22:20:53 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/7&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/080411100041&#39;]}
2022-06-29 22:20:53 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/c_search/byprod/10/8&gt; (referer: None)
2022-06-29 22:20:53 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/c_search/byprod/10/5&gt; (referer: None)
2022-06-29 22:20:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/4&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100124&#39;]}
2022-06-29 22:20:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/4&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100072&#39;]}
2022-06-29 22:20:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/4&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100152&#39;]}
2022-06-29 22:20:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/4&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100114&#39;]}
2022-06-29 22:20:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/4&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100036&#39;]}
2022-06-29 22:20:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/8&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/080411100012&#39;]}
2022-06-29 22:20:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/8&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100170&#39;]}
2022-06-29 22:20:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/8&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/050411100558&#39;]}
2022-06-29 22:20:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/8&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100133&#39;]}
2022-06-29 22:20:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/8&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/080411100010&#39;]}
2022-06-29 22:20:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/5&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/070411100029&#39;]}
2022-06-29 22:20:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/5&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/060411100824&#39;]}
2022-06-29 22:20:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/5&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/060411100772&#39;]}
2022-06-29 22:20:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/5&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/080411100001&#39;]}
2022-06-29 22:20:54 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/c_search/byprod/10/5&gt;

{&#39;link&#39;: [&#39;https://pta.trunojoyo.ac.id/welcome/detail/060411100801&#39;]}
2022-06-29 22:20:54 [scrapy.core.engine] INFO: Closing spider (finished)
2022-06-29 22:20:54 [scrapy.extensions.feedexport] INFO: Stored csv feed (40 items) in: link.csv
2022-06-29 22:20:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{&#39;downloader/request_bytes&#39;: 2141,
 &#39;downloader/request_count&#39;: 9,
 &#39;downloader/request_method_count/GET&#39;: 9,
 &#39;downloader/response_bytes&#39;: 42518,
 &#39;downloader/response_count&#39;: 9,
 &#39;downloader/response_status_count/200&#39;: 9,
 &#39;elapsed_time_seconds&#39;: 2.248695,
 &#39;feedexport/success_count/FileFeedStorage&#39;: 1,
 &#39;finish_reason&#39;: &#39;finished&#39;,
 &#39;finish_time&#39;: datetime.datetime(2022, 6, 29, 15, 20, 54, 49940),
 &#39;httpcompression/response_bytes&#39;: 141698,
 &#39;httpcompression/response_count&#39;: 8,
 &#39;item_scraped_count&#39;: 40,
 &#39;log_count/DEBUG&#39;: 58,
 &#39;log_count/INFO&#39;: 11,
 &#39;response_received_count&#39;: 9,
 &#39;robotstxt/request_count&#39;: 1,
 &#39;robotstxt/response_count&#39;: 1,
 &#39;robotstxt/response_status_count/200&#39;: 1,
 &#39;scheduler/dequeued&#39;: 8,
 &#39;scheduler/dequeued/memory&#39;: 8,
 &#39;scheduler/enqueued&#39;: 8,
 &#39;scheduler/enqueued/memory&#39;: 8,
 &#39;start_time&#39;: datetime.datetime(2022, 6, 29, 15, 20, 51, 801245)}
2022-06-29 22:20:54 [scrapy.core.engine] INFO: Spider closed (finished)
</pre></div>
</div>
</div>
</div>
</section>
<section id="crawling-detail-pta">
<h2>Crawling Detail PTA<a class="headerlink" href="#crawling-detail-pta" title="Permalink to this headline">#</a></h2>
<p>Pada bagian ini digunakan untuk membuat dan menjalankan program python. Program tersebut digunakan untuk melakukan crawling 40 detail tugas akhir informatika. Untuk melakukan crawling menggunakan library scrapy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> -a detail.py
<span class="c1"># Membuat file detail.py</span>
<span class="c1"># File detail.py digunakan untuk crawling detail tugas akhir</span>
<span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;quotes&quot;</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">dataCSV</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;link.csv&#39;</span><span class="p">)</span>
        <span class="n">indexData</span> <span class="o">=</span> <span class="n">dataCSV</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">arrayData</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indexData</span><span class="p">:</span>
            <span class="n">ambil</span> <span class="o">=</span> <span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">arrayData</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ambil</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">arrayData</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">yield</span> <span class="p">{</span>
            <span class="s1">&#39;judul&#39;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;#content_journal &gt; ul &gt; li &gt; div:nth-child(2) &gt; a::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">(),</span>
            <span class="s1">&#39;penulis&#39;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;#content_journal &gt; ul &gt; li &gt; div:nth-child(2) &gt; div:nth-child(2) &gt; span::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">(),</span>
            <span class="s1">&#39;pembimbing_1&#39;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;#content_journal &gt; ul &gt; li &gt; div:nth-child(2) &gt; div:nth-child(3) &gt; span::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">(),</span>
            <span class="s1">&#39;pembimbing_2&#39;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;#content_journal &gt; ul &gt; li &gt; div:nth-child(2) &gt; div:nth-child(4) &gt; span::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">(),</span>
            <span class="s1">&#39;abstrak&#39;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;#content_journal &gt; ul &gt; li &gt; div:nth-child(4) &gt; div:nth-child(2) &gt; p::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Appending to detail.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menjalankan file detail.py untuk melakukan proses crawling detail tugas akhir</span>
<span class="c1"># Hasil akan disimpan dalam file detail.csv</span>
<span class="c1"># File detail.csv digunakan sebagai dataset utama yang diolah dalam proyek ini</span>
<span class="o">!</span>scrapy runspider detail.py -o detail.csv
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Python310\lib\site-packages\scrapy\spiderloader.py:37: UserWarning: There are several spiders with the same name:

  QuotesSpider named &#39;quotes&#39; (in crawlproject.spiders.detail)

  QuotesSpider named &#39;quotes&#39; (in crawlproject.spiders.link)

  This can cause unexpected behavior.
  warnings.warn(
2022-06-29 22:20:55 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: crawlproject)
2022-06-29 22:20:55 [scrapy.utils.log] INFO: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021), cryptography 36.0.1, Platform Windows-10-10.0.19044-SP0
2022-06-29 22:20:55 [scrapy.crawler] INFO: Overridden settings:
{&#39;BOT_NAME&#39;: &#39;crawlproject&#39;,
 &#39;NEWSPIDER_MODULE&#39;: &#39;crawlproject.spiders&#39;,
 &#39;ROBOTSTXT_OBEY&#39;: True,
 &#39;SPIDER_LOADER_WARN_ONLY&#39;: True,
 &#39;SPIDER_MODULES&#39;: [&#39;crawlproject.spiders&#39;]}
2022-06-29 22:20:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2022-06-29 22:20:55 [scrapy.extensions.telnet] INFO: Telnet Password: d0fe8e468b10882c
2022-06-29 22:20:55 [scrapy.middleware] INFO: Enabled extensions:
[&#39;scrapy.extensions.corestats.CoreStats&#39;,
 &#39;scrapy.extensions.telnet.TelnetConsole&#39;,
 &#39;scrapy.extensions.feedexport.FeedExporter&#39;,
 &#39;scrapy.extensions.logstats.LogStats&#39;]
2022-06-29 22:20:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
[&#39;scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.retry.RetryMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.redirect.RedirectMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.cookies.CookiesMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware&#39;,
 &#39;scrapy.downloadermiddlewares.stats.DownloaderStats&#39;]
2022-06-29 22:20:55 [scrapy.middleware] INFO: Enabled spider middlewares:
[&#39;scrapy.spidermiddlewares.httperror.HttpErrorMiddleware&#39;,
 &#39;scrapy.spidermiddlewares.offsite.OffsiteMiddleware&#39;,
 &#39;scrapy.spidermiddlewares.referer.RefererMiddleware&#39;,
 &#39;scrapy.spidermiddlewares.urllength.UrlLengthMiddleware&#39;,
 &#39;scrapy.spidermiddlewares.depth.DepthMiddleware&#39;]
2022-06-29 22:20:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2022-06-29 22:20:55 [scrapy.core.engine] INFO: Spider opened
2022-06-29 22:20:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-06-29 22:20:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-06-29 22:20:56 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/robots.txt&gt; (referer: None)
2022-06-29 22:20:56 [filelock] DEBUG: Attempting to acquire lock 2185426509712 on C:\Users\Acer\.cache\python-tldextract\3.10.1.final__Python310__a9c9a9__tldextract-3.2.0\publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
2022-06-29 22:20:56 [filelock] DEBUG: Lock 2185426509712 acquired on C:\Users\Acer\.cache\python-tldextract\3.10.1.final__Python310__a9c9a9__tldextract-3.2.0\publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
2022-06-29 22:20:56 [filelock] DEBUG: Attempting to acquire lock 2185426515328 on C:\Users\Acer\.cache\python-tldextract\3.10.1.final__Python310__a9c9a9__tldextract-3.2.0\urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
2022-06-29 22:20:56 [filelock] DEBUG: Lock 2185426515328 acquired on C:\Users\Acer\.cache\python-tldextract\3.10.1.final__Python310__a9c9a9__tldextract-3.2.0\urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
2022-06-29 22:20:56 [filelock] DEBUG: Attempting to release lock 2185426515328 on C:\Users\Acer\.cache\python-tldextract\3.10.1.final__Python310__a9c9a9__tldextract-3.2.0\urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
2022-06-29 22:20:56 [filelock] DEBUG: Lock 2185426515328 released on C:\Users\Acer\.cache\python-tldextract\3.10.1.final__Python310__a9c9a9__tldextract-3.2.0\urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
2022-06-29 22:20:56 [filelock] DEBUG: Attempting to release lock 2185426509712 on C:\Users\Acer\.cache\python-tldextract\3.10.1.final__Python310__a9c9a9__tldextract-3.2.0\publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
2022-06-29 22:20:56 [filelock] DEBUG: Lock 2185426509712 released on C:\Users\Acer\.cache\python-tldextract\3.10.1.final__Python310__a9c9a9__tldextract-3.2.0\publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
2022-06-29 22:20:56 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/040411100468&gt; (referer: None)
2022-06-29 22:20:56 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/040411100468&gt;

{&#39;judul&#39;: [&#39;PERANCANGAN DAN IMPLEMENTASI SISTEM DATABASE \r\nTERDISTRIBUSI MENGGUNAKAN ORACLE STUDI KASUS \r\nSIAKAD UNIVERSITAS TRUNOJOYO&#39;], &#39;penulis&#39;: [&#39;Penulis : A.Ubaidillah S.Kom&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Budi Setyono M.T&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Hermawan S.T&#39;], &#39;abstrak&#39;: [&#39;Sistem  informasi  akademik  (SIAKAD) merupakan  sistem  informasi  yang  berfungsi  menangani pengelolaan  dan  penyajian  data-data  akademik,  yang  oleh pihak  fakultas  SIAKAD  dianggap  sangat  penting  dalam memberikan  pelayanan  mahasiswa  yang  membutuhkan informasi akademik. Di Universitas Trunojoyo telah tersedia SIAKAD,  namun  masih  menggunakan  database  terpusat. Sistem seperti ini memberikan kelebihan yaitu perawatannya mudah  selain  itu  juga  membutuhkan  sedikit  biaya,  namun sistem  tersebut  juga  berpotensi  mengahadapi  kendala-kendala  yaitu  dalam  proses  transaksi  data  karena  padatnya jaringan yang menuju database SIAKAD, kelambatan dalam pemrosesan  respon  query  dikarenakan  data  yang  tersimpan semakin besar dan pemrosesan semakin kompleks, dan  juga memiliki kelemahan dalam hal ketersediaan data. Untuk  itu sistem  seperti  ini  memerlukan  pengembangan  sistem database  yang  lebih  baik  dengan  menggunakan  sistem databases  terdistribusi  pada  masing-masing  fakultas  yang dapat  dijadikan  solusi  bagi  permasalahan  di  atas.  Karena dalam basisdata terdistribusi terdapat keuntungan yang tidak dimiliki oleh basisdata  terpusat yaitu pengawasan distribusi, reability,  availability,  kecepatan  dalam  pemrosesan  query dan otonomi local&#39;]}
2022-06-29 22:20:56 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/040411100480&gt; (referer: None)
2022-06-29 22:20:56 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/080411100115&gt; (referer: None)
2022-06-29 22:20:57 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/080411100102&gt; (referer: None)
2022-06-29 22:20:57 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/040411100480&gt;

{&#39;judul&#39;: [&#39;RANCANG BANGUN APLIKASI PROXY SERVER UNTUK\r\nENKRIPSI KODE HTML MENGGUNAKAN\r\nALGORITMA BLOWFISH&#39;], &#39;penulis&#39;: [&#39;Penulis : Akhmad Suyandi, S.Kom&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Drs. Budi Soesilo, M.T&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Hermawan, ST, MT&#39;], &#39;abstrak&#39;: [&#39;Web server adalah sebuah perangkat lunak server yang berfungsi\r\nmenerima permintaan HTTP atau HTTPS dari web client dan\r\nmengirimkan jawaban dalam bentuk halaman-halaman web yang\r\numumnya berbentuk dokumen HTML. Dokumen HTML yang dikirim\r\nmerupakan dokumen yang dibentuk dari bahasa markup yang plaintext.\r\nArtinya, dokumen berisi kode-kode HTML murni tanpa proses enkripsi.\r\nTujuan dari penelitan ini adalah membuat sebuah aplikasi proxy\r\nserver yang menerima permintaan HTTP dari web client dan\r\nmeneruskannya ke web server. Kemudian aplikasi ini akan menerima\r\nrespon dari server dan melakukan proses enkripsi pada dokumen HTML\r\nterlebih dahulu. Sehingga dokumen HTML yang dikirim kepada web\r\nclient sudah berbentuk dokumen HTML yang terenkripsi. Web client\r\ndisini bisa berupa aplikasi seperti Internet Explorer, Mozilla Firefox,\r\natau Opera. Aplikasi-aplikasi tersebut biasa dikenal dengan sebutan web\r\nbrowser.\r\nKetika web browser menerima dokumen HTML yang terenkripsi\r\ndari aplikasi proxy server, maka JavaScript Engine yang ada di web\r\nbrowser akan melakukan proses dekripsi sekaligus rendering sehingga\r\ndokumen akan ditampilkan sesuai dengan aslinya. Namun apabila kode\r\ndari dokumen HTML tersebut dilihat melalui menu view source yang\r\nada di web browser akan didapatkan dokumen HTML yang tetap\r\nterenkripsi.&#39;]}
2022-06-29 22:20:57 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/080411100115&gt;

{&#39;judul&#39;: [&#39;SISTEM AUGMENTED REALITY ANIMASI BENDA BERGERAK MENGGUNAKAN FLARTOOLKIT&#39;], &#39;penulis&#39;: [&#39;Penulis : Septian Rahman Hakim&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Arik Kurniawati, S.Kom., M.T.&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Haryanto, S.T., M.T.&#39;], &#39;abstrak&#39;: [&#39;Seiring perkembangan teknologi yang ada didunia, muncul teknologi yang disebut augmented reality. Augmented Reality (AR) merupakan upaya untuk menggabungkan dunia maya dan dunia virtual yang dibuat melalui komputer sehingga batas antara keduanya menjadi sangat tipis. Head-Mounted Display (HMD) merupakan contoh hasil dari penelitian tentang Augmented Reality, ini merupakan satu-satunya peralatan dasar dalam teknologi-teknologi terbaru. Seiring berjalannya waktu, augmented reality berkembang pesat sehingga memungkinkan pengembangan aplikasi ini di berbagai bidang.\r\n\r\nUntuk mengembangkan AR banyak sekali library pendukung yang dapat digunakan. FlarToolKit adalah salah satunya. FlarToolKit merupakan library pendukung augmented reality pada platform flash.\r\n\r\nBerdasarkan sistem AR animasi benda bergerak yang dibuat adalah animasi bergerak permainan pingpong dimana telah dikolaborasikan dengan augmented reality untuk menggerakkan setiap langkah dari playernya. Interaksi antar obyek tersebut dapat dilihat dari gerak bola yang dapat dipukul dengan obyek virtual yang ditampilkan melalui augmented reality.\r\n&#39;]}
2022-06-29 22:20:57 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/080411100102&gt;

{&#39;judul&#39;: [&#39;Aplikasi Penilaian Kinerja dengan Metodologi Customer Realtionship Management (CRM)&#39;], &#39;penulis&#39;: [&#39;Penulis : Luthfi Zahro&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Moch. Kautsar Sophan, S.Kom., M.MT&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Dr. Rachmad Hidayat, ST., MT&#39;], &#39;abstrak&#39;: [&#39;Setiap perusahaan mengharapkan adanya hubungan baik dengan pelanggan, begitupun dengan PT. X sebagai perusahaan yang bergerak di bidang minyak dan gas bumi Negara. Pengelolaan hubungan yang baik akan berdampak pada peningkatan citra perusahaan dimata pelanggan. Penilaian kinerja perusahaan dapat diukur dengan menggunakan kriteria dari CRM Scorecard. CRM Scorecard diambil dari Balanced Scorecard (BSC) dengan berfokus pada pelanggan. Adanya penilaian kinerja dengan metode Analytic Network Process (ANP) untuk pembobotan, PT. X dapat  menilai kinerja perusahaan dengan ditunjukkan oleh Traffic Light System sebagai hasilnya. Hasil scoring KPI menunjukkan bahwa terdapat 2 KPI yang berada pada level buruk, yaitu Ekuitas Pelanggan dan Sistem Penghargaan. Kedua KPI ini diperlukan perhatian yang lebih. Indikator yang berada pada level cukup ada 3 KPI, yaitu yaitu Perluasan Pelanggan, Teknologi Informasi, dan Struktur Organisasi. Perusahaan harus berhati-hati dengan berbagai macam kemungkinan yang dapat terjadi. Indikator yang berada pada level baik ada 9 KPI, yaitu Profitabilitas, Kesetiaan Pelanggan, Kepuasan Pelanggan, Nilai Hubungan dengan Pelanggan, Perolehan Pelanggan, Mempertahankan Pelanggan, Peranan Manajemen, Pelatihan, dan Kerjasama.\r\n\r\nKata Kunci:  Sistem Penilaian Kinerja, CRM Scorecard,  Analytic Network Process (ANP), Key     Performance Indicator (KPI)\r\n&#39;]}
2022-06-29 22:20:57 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/040411100476&gt; (referer: None)
2022-06-29 22:20:57 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/040411100476&gt;

{&#39;judul&#39;: [&#39;APLIKASI KONTROL DAN MONITORING JARINGAN KOMPUTER BERBASIS MOBILE&#39;], &#39;penulis&#39;: [&#39;Penulis : M. Basith Ardianto,&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Drs. Budi Soesilo, MT&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Koko Joni, ST&#39;], &#39;abstrak&#39;: [&#39;Berjalannya koneksi jaringan komputer dengan lancar dan tanpa gangguan merupakan harapan seluruh penggunanya,\r\nterutama pihak yang bertanggung jawab pada bidang itu, yakni administrator jaringan. Namun tidak selamanya koneksi\r\njaringan dapat berjalan dengan lancar tanpa adanya gangguan. Kenyataan di lapangan terutama pada jaringan komputer skala\r\nbesar, berpotensi besar terjadi gangguan atau bahkan kerusakan koneksi jaringan komputer.\r\nHal ini rata - rata disebabkan banyaknya penggunaan serta padatnya traffic data dalam jaringan komputer itu sendiri.\r\nOleh karena itu untuk menjaga bahkan meningkatkan kualitas layanan koneksi jaringan maka diperlukan adanya akses kontrol\r\ndan monitoring pada level administrator jaringan secara real-time berbasis mobile, yang dapat mengatur dan mengetahui\r\ninformasi tentang koneksi jaringan dan dapat diakses setiap saat.\r\nPihak administrator jaringan dituntut untuk terlebih dahulu mengetahui adanya gangguan atau bahkan terputusnya\r\nkoneksi jaringan walaupun administrator tidak berada di tempat kontrol dan monitoring, Dengan adanya sistem kontrol dan\r\nmonitoring berbasis mobile, diharapkan dapat membantu tugas administrator dalam mengontrol dan memantau jaringan serta\r\ndalam mengambil kebijakan atas node – node yang terkoneksi pada jaringan yakni memanajemen koneksi, port dan bandwidth\r\nsetiap saat dan secara mobile. agar dengan segera dapat melakukan pembenahan ketika terjadi gangguan jaringan sebelum\r\npemakai jaringan (klien) melakukan pengaduan atas adanya gangguan.\r\nKata Kunci : Administrator Jaringan, Koneksi Jaringan, Akses Kontrol dan Monitoring.&#39;]}
2022-06-29 22:20:57 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100070&gt; (referer: None)
2022-06-29 22:20:57 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/060411100755&gt; (referer: None)
2022-06-29 22:20:57 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/050411100662&gt; (referer: None)
2022-06-29 22:20:57 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100070&gt;

{&#39;judul&#39;: [&#39;SISTEM PENDUKUNG KEPUTUSAN OPTIMASI PENJADWALAN MATAKULIAH UNTUK PENGGUNAAN RUANGAN KULIAH BERSAMA DI UNIVERSITAS TRUNOJOYO MADURA MENGGUNAKAN ALGORITMA  \r\nGENETIKA&#39;], &#39;penulis&#39;: [&#39;Penulis : Heri Supriyanto&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Mulaab, S.Si., M.Kom&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Firli Irhamni, ST., M.Kom&#39;], &#39;abstrak&#39;: [&#39;Penjadwalan  kuliah  di  Perguruan  Tinggi  merupakan  masalah yang  kompleks.  Dalam  permasalahan tersebut  terdapat  beberapa variabel  yang  harus  dipertimbangkan  supaya  mendapatkan  jadwal  yang \r\noptimal. Di dalam penyusunan jadwal kuliah ini terdapat sangat banyak kemungkinan  yang  selayaknya  dicoba  untuk  menemukan  penjadwalan yang  terbaik.  Karena  itu  dibutuhkan  metode  optimasi  yang  dapat diterapkan  untuk  mengerjakan  penjadwalan  mata  kuliah  ini.  Metode yang  dapat  digunakan  untuk  menyelesaikan  permasalahan  tersebut adalah  dengan  menggunakan  Algoritma  Genetika.  Tugas  Akhir  ini \r\nbertujuan  untuk  membuat  suatu  sistem  yang  dapat  membuat  jadwal matakuliah  secara  otomatis  dan  hasilnya  optimal.  Dari  hasil  penelitian yang  dilakukan  algoritma  genetika  mampu  membuat  jadwal  dengan \r\noptimal  yang  dibuktikan  dari  nilai  fitness  yang memiliki  nilai  1  secara otomatis  jadwal  yang  dibentuk  akan  optimal.  Semoga  adanya  aplikasi ini  diharapkan  bisa  mempermudah  didalam  pembuatan  penjadwalan \r\nmatakuliah dengan mudah dan cepat. \r\n \r\nKata Kunci: Algoritma Genetika, Optimasi,  Penjadwalan.&#39;]}
2022-06-29 22:20:57 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/060411100755&gt;

{&#39;judul&#39;: [&#39;RANCANG BANGUN MANAJEMEN PEMBELAJARAN DAN TES TOEFL BERBASIS MOBILE&#39;], &#39;penulis&#39;: [&#39;Penulis : Susanto&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Hermawan S.T.,M.Kom&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Andharini Dwi Cahyani S.Kom.,M.Kom&#39;], &#39;abstrak&#39;: [&#39;Penggunaan teknologi mobile saat ini sangat marak, disamping keunggulannya dapat mudah bawa dibawa kemana-mana, teknologi mobile sekarang sangat mudah untuk dieksplorasi, terbukti dengan adanya smartphone yang mempunyai banyak layanan yang dapat bermanfaat bagi para penggunanya. Toefl (Test Of English As A Foreign Languange) sangat dibutuhkan dalam menghadapi kemajuan teknologi saat ini, Kurang besarnya minat masyarakat dalam belajar bahasa inggris dan mengikuti tes-tes Toefl yang ada, berpengaruh pada kemajuan teknologi.  Android  merupakan  subset  perangkat  lunak  untuk perangkat  mobile  yang  meliputi  sistem  operasi, middleware,  dan  aplikasi  inti  yang  di  release  oleh Google. Android SDK adalah  tools  API (Application Programming Interface)  yang digunakan untuk memulai membuat aplikasi pada platform Android dengan menggunakan bahasa pemrograman Java. Eclipse adalah sebuah IDE (Integrated Development Environment) yang digunakan dalam  coding  aplikasi Android nantinya. Salah satu pemanfaatan teknologi mobile yaitu dengan membuat media pembelajaran dan tes TOEFL baik soal berupa teks dan audio dengan menggunakan  teknologi Android, tentunya berbasis mobile. Dengan tes TOEFL, pembelajaran test dan kelebihan listening menu di dalam aplikasi ini, diharapkan akan dapat membatu meningkatkan pemahaman pengguna mengenai tes TOEFL.\r\n\r\nKata Kunci: tes TOEFL, ANDROID, Java , Mobile, SDK\r\n&#39;]}
2022-06-29 22:20:57 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/050411100662&gt;

{&#39;judul&#39;: [&#39;Kalibrasi Kamera dengan Menggunakan Metode Tsai&#39;], &#39;penulis&#39;: [&#39;Penulis : Bima Iffan Hakim&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Eza Rahmanita, ST., MT&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Meidya Koeshardianto, S.Si., MT&#39;], &#39;abstrak&#39;: [&#39;Teknik kalibrasi sangat berpengaruh terhadap perkembangan computer vision karena setiap proses dalam teknik kalibrasi sangat diperlukan untuk pengolahan lanjutan berbagai macam proses vision. Dengan dilakukannya kalibrasi, proses vision akan menjadi lebih mudah. Dalam prosesnya teknik kalibrasi dilakukan untuk menentukan parameter yang dapat dilakukan untuk proses vision selanjutnya diantaranya rekonstruksi 3D. Penelitian ini mencoba mengangkat kembali teknik kalibrasi kamera klasik yang sangat popular, yaitu teknik kalibrasi kamera dengan menggunakan algoritma Tsai. Sebagai simulasi, hasil parameter yang akan didapat akan digunakan untuk melakukan pengukuran tinggi obyek dengan aplikasi dan kemudian dibandingkan dengan tinggi obyek secara real. Dari hasil ujicoba, didapatkan hasil bahwa tahapan proses kalibrasi kamera dengan metode Tsai berhasil dilakukan. Kemudian data parameter yang didapat, dilakukan simulasi dengan ujicoba sebanyak 5 skenario dengan masing-masing skenario dilakukan dengan 2 percobaan. Hasil yang didapat dari hasil pengukuran dengan aplikasi ternyata masih jauh dari hasil pengukuran secara nyata. Galat relative yang didapat dari perhitungan dengan aplikasi rata-rata hanya 50.6% dari perhitungan secara nyata. Hasil ini disebabkan karena proses pengambilan data awal dengan spesifikasi yang terbatas.\n\nKata kunci : kalibrasi kamera, algoritma tsai, computer vision&#39;]}
2022-06-29 22:20:58 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/080411100014&gt; (referer: None)
2022-06-29 22:20:58 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/080411100014&gt;

{&#39;judul&#39;: [&#39;PENERAPAN METODE ANALYTICAL HIERARCHY PROCESS DAN FUZZY MULTI-OBJECTIVE PROGRAMMINGUNTUK PEMILIHAN SUPPLIER&#39;], &#39;penulis&#39;: [&#39;Penulis : Helyatin&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Bain Khusnul K, S.T.,M.Kom&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Andharini Dwi C, S.Kom.,M.Kom&#39;], &#39;abstrak&#39;: [&#39;Pemilihan  supplier merupakan salah satu isu penting, karena  pemilihan supplier menjadi bagian dari sebuah  supply chain maka hubungan tersebut akan memiliki pengaruh yang sangat besar terhadap kelangsungan produksi.Pada tugas akhir ini dianalisa mengenai  Analytic Hierarchy Process (AHP) dan Fuzzy Multi-Objective Programming (FMOP) untuk pemilihan supplier di Industri Batik Podhek Pemekasan. Perhitungan AHP akan diperoleh nilai bobot tiap kriteria pemilihan supplier yang nantinya akan jadi nilai masukan pada FMOP. FMOP memberikan solusi memaksimalkan dan meminimalkan tujuan.Setelah dilakukan proses perhitungan faktor kriteria yang paling memberikan kontribusi terhadap pemilihan supplier adalah kriteria harga (0.52), kualitas (0.2) dan tingkat cacat (0.2), dan keterlambatan pengiriman (0.08). Dari hasil penelitian diperoleh bahwa supplier paling optimum adalah  Toko Utara. Untuk bahan baku kain dengan batasan pembelian 0 - 500 lembar didapatkan hasil z1 = 380, z2 = 415, z3 = 85, z4 = 250. Untuk bahan baku pewarna dan malan dengan batasan pembelian 0 - 250 kg didapatkan hasil z1 = 0, z2 = 220, z3 = 30, z4 = 125, dan z1 = 147.5, z2 = 225, z3 = 25, z4 = 125.\r\n\r\nKata kunci  :Supply Chain Management (SCM), pemilihan supplier, Analytical Hierarchy Process, Fuzzy, Multi-Objective Programming.&#39;]}
2022-06-29 22:20:58 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/080411100041&gt; (referer: None)
2022-06-29 22:20:58 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100124&gt; (referer: None)
2022-06-29 22:20:58 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100072&gt; (referer: None)
2022-06-29 22:20:58 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/080411100041&gt;

{&#39;judul&#39;: [&#39;Model Penjualan Produk Unggulan Batik Khas Pamekasan Berbasis Electronic Commerce&#39;], &#39;penulis&#39;: [&#39;Penulis : Murni Rotifah&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I :  Moch. Kautsar Sophan, S.Kom, M.MT&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Bain Khusnul Khotimah, S.T., M.Kom      &#39;], &#39;abstrak&#39;: [&#39;Kabupaten Pamekasan merupakan salah satu pusat industri dan perdagangan batik tulis yang dapat diandalkan sebagai salah satu sumber pendapatan daerah. Batik tulis Madura, khususnya batik tulis Pamekasan memiliki corak dan design yang khas. Penulis meneliti tentang pembuatan Model Penjualan Produk Unggulan Batik khas Pamekasan berbasis Electronic Commerce. Tujuan penelitian ini adalah Membangun model e-commerce yang interaktif untuk mendukung potensi perindustrian dan perdagangan kabupaten Pamekasan serta mempermudah transaksi penjualan produk unggulan batik tulis khas Pamekasan. Model e-commerce yang diterapkan adalah business to customer (B2C). Metodologi dalam mengerjakan penelitian ini adalah metode SDLC (Software Development Life Cycle), dengan menggunakan SDLC waterfall. Berdasarkan hasil analisis kuisioner yang dibagikan kepada pelanggan dan umum yaitu sebanyak 50 responden, yang mencakup beberapa pertanyaan mengenai fitur-fitur pada website. Simpulan yang dapat diambil yaitu pemodelan yang dibuat cukup baik untuk diimplementasikan menjadi website e-commerce. Hal ini dibuktikan dari hasil kuisoner menunjukkan rata-rata persentase responden yang menjawab setuju mencapai 53%. \r\n\r\nKata kunci : Batik, E-Commerce, B2C, Model\r\n&#39;]}
2022-06-29 22:20:58 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100124&gt;

{&#39;judul&#39;: [&#39;SISTEM PENENTUAN STATUS GIZI PASIEN RAWAT INAP\r\nMENGGUNAKAN METODE NAÏVE BAYES CLASSIFIER\r\n(STUDI KASUS : RSUD DR. H. SLAMET\r\nMARTODIRDJO PAMEKASAN)&#39;], &#39;penulis&#39;: [&#39;Penulis : Nur Anggraeni&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Diana Rahmawati, ST.M.T&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Firli Irhamni, ST.M.Kom&#39;], &#39;abstrak&#39;: [&#39;Di Indonesia masalah perkembangan gizi adalah masalah yang\r\nperlu perhatian lebih. Jika seseorang tidak mengetahui tentang status\r\ngizinya, maka tidak akan dapat mengontrol berapa banyak jumlah gizi\r\nyang dibutuhkan dalam tubuh. Dalam penelitian ini dirancang aplikasi\r\nsistem pendukung keputusan yang digunakan untuk menentukan status\r\ngizi pasien dan memberikan solusi makanan pada pasien sesuai riwayat\r\npenyakit yang di derita pasien. Sistem yang dirancang ini berbasis Web,\r\ndan memudahkan pihak admin atau ahli gizi rumah sakit dalam\r\npenentuan status gizi pasien. Diharapkan dengan adanya aplikasi ini\r\ndapat memberikan efisien dan efektifitas kinerja setiap pihak.\r\nMetode yang digunakan dalam penelitian ini menggunakan\r\nNaïve Bayes Classifier (NBC). Metode terbaru yang di gunakan untuk\r\nmemprediksi probabilitas.Metode Naïve bayes Classifier melakukan\r\nproses penentuan perhitungan probabilitas status gizi. Dimana dicari\r\nnilai probabilitas terbesar yang kemudian menjadi kesimpulan\r\npenentuan status gizi.\r\nMetode ini dapat diterapkan dalam studi kasus Sistem\r\nPenentuan Status Gizi Pasien dengan hasil akurasi terbesar 92%.\r\nKata Kunci : Naïve Bayes Classifier, Sistem Pendukung Keputusan,\r\nStatus Gizi, Web&#39;]}
2022-06-29 22:20:58 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100072&gt;

{&#39;judul&#39;: [&#39;PENGENALAN TULISAN TANGAN HURUF ALFABET\r\nDENGAN METODE MODIFIED DIRECTION FEATURE (MDF)\r\nDAN LEARNING VECTOR QUANTIZATION (LVQ)&#39;], &#39;penulis&#39;: [&#39;Penulis : Hilyati Safitri&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Fitri Damayanti S.Kom., M.Kom&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Kurniawan Eka Permana S.Kom., M.Sc.&#39;], &#39;abstrak&#39;: [&#39;Pengenalan tulisan tangan merupakan topik penelitian yang sangat populer saat ini. Para peneliti telah banyak melakukan usaha-usaha untuk membuat sistem pengenalan tulisan tangan otomatis dengan berbagai teknik yang berbeda. Penelitian ini membahas pengembangan sistem pengenalan tulisan tangan offline yang menggunakan pencirian lokal dari karakter-karakter tulisan tangan. Salah satu faktor penentu dalam pengenalan tulisan tangan adalah model atau bentuk tulisan tangan dari penulis yang mampu dikenali. Tiap penulis pasti memiliki gaya menulis atau bentuk tulisan tangan yang berbeda. Metode yang digunakan untuk pengenalan pola tulisan tangan pada penelitian ini adalah Modified Direction Feature (MDF) untuk proses ekstraksi fitur dan Learning Vector Quantization (LVQ) untuk proses klasifikasi. Proses ekstraksi fitur pada metode MDF dilakukan dengan cara penentuan arah garis dan posisi  dari tiap-tiap piksel. Sedangkan untuk proses pelatihan data menggunakan  metode Learning Vector Quantization (LVQ), metode ini akan menghasilkan bobot yang akan digunakan untuk proses pengenalan citra huruf tulisan tangan. Dari uji coba yang dilakukan pada sistem, hasil terbaik untuk pengenalan citra huruf tulisan tangan diperoleh dengan jumlah data pelatihan sebanyak 260 citra dan data uji coba sebanyak 52 citra. Hasil akurasi sistem yang didapatkan sebesar 71,15 %.\r\n\r\nKata Kunci: Tulisan Tangan, Modified Direction Feature, Learning Vector Quantization&#39;]}
2022-06-29 22:20:58 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100152&gt; (referer: None)
2022-06-29 22:20:58 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100152&gt;

{&#39;judul&#39;: [&#39;PENGENALAN POLA SENYUMAN BERBASIS EKSTRAKSI FITUR PRINCIPAL COMPONENT ANALYSIS (PCA) DAN LINIER DESCRIMINANT ANALYSIS (LDA)&#39;], &#39;penulis&#39;: [&#39;Penulis : SITI KHOLILAH&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : RIMA TRI WAHYUNINGRUM, S.T., M.T&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :HARYANTO, S.T., M.T&#39;], &#39;abstrak&#39;: [&#39;Citra senyum merupakan salah satu fitur biometrik yang dapat dijadikan sebagai bukti autentik dari seseorang. Sistem pengenalan pola (pattern recognition) secara komputerisasi, akan mengetahui identitas atau ciri diri seseorang. Pengenalan senyum telah banyak diteliti oleh banyak kalangan. Salah satu bentuk penerapan pengenalan pola senyum ini adalah mengetahui senyum seseorang sehingga nantinya senyum tersebut dapat dikenali oleh komputer dan disimpan dalam database. Terdapat dua cara untuk menentukan pola senyuman yaitu secara manual dan otomatis. Secara manual dapat dilakukan dengan kasat mata, sedangkan secara otomatis dapat di tentukan dengan menggunakan suatu sistem. Pada  Tugas Akhir ini, mengidentifikasi senyuman secara otomatis digunakan metode Principal Component Analysis (PCA) dan Linier Descriminant Analysis (LDA), dimana jenis senyuman pada tugas akhir ini dibagi menjadi lima bagian, yaitu senyum manis, senyum mengejek, senyum yang dipaksakan, senyum tertutup dan senyum terbuka. Penggunaan metode ekstraksi fitur  yang tepat dan efisien  sangat menentukan keberhasilan dari sistem pengenalan pola secara keseluruhan. Untuk metode klasifikasi pengenalan pola menggunakan Euclidean Distance atau Manhattan Distance. Dari hasil uji coba menggunakan 175 gambar data pelatihan didapatkan tingkat akurasi PCA adalah 89.8% pada ordered3. Sedangkan hasil uji coba menggunakan PCA &amp; LDA didapatkan tingkat akurasi 100% pada ordered3.&#39;]}
2022-06-29 22:20:59 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100114&gt; (referer: None)
2022-06-29 22:20:59 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100120&gt; (referer: None)
2022-06-29 22:20:59 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100036&gt; (referer: None)
2022-06-29 22:20:59 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100114&gt;

{&#39;judul&#39;: [&#39;SISTEM PEROLEHAN CITRA BERBASIS ISI MENGGUNAKAN\r\nGRAY LEVEL DIFFERENCE METHOD BERDASARKAN\r\nCIRI TEKSTUR PADA POLA BATIK\r\n&#39;], &#39;penulis&#39;: [&#39;Penulis : Nansy Lovitasari&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Fitri Damayanti, S.Kom., M.Kom&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Rima Tri Wahyuningrum, S.T., M.T&#39;], &#39;abstrak&#39;: [&#39;Batik adalah kerajinan yang memiliki nilai seni tinggi dan telah menjadi bagian dari budaya Indonesia sejak lama. Batik di Indonesia mempunyai beragam jenis tekstur batik, warna batik, dan pola batik yang mencerminkan asal usul daerah dari batik tersebut. Saat ini pencarian citra berbasis teks sudah tidak efektif lagi karena adanya penilaian subjektif dari pengguna dalam merepresentasikan suatu citra. Karena itu diperlukan suatu sistem yang dapat menangani pencarian citra menggunakan query berupa citra atau disebut Sistem Perolehan Citra berbasis Isi (SPCI) atau Content Based Image Retrieval (CBIR). Penelitian  ini menggunakan ciri tekstur sebagai proses pencarian kemiripan dari delapan kelas citra batik yang  berbeda yaitu: Cirebon, Bali, Bangkalan, Pamekasan, Sumenep, Yogyakarta, Solo, dan Pekalongan sebagai objek perolehan citra berbasis isi. Sistem dibangun dengan proses utamanya yaitu ekstraksi fitur tekstur dengan menggunakan metode Gray Level Difference Method (GLDM) menggunakan empat arah utama. GLDM menghitung perbedaan mutlak antara sepasang derajat keabuan yang terpisah oleh jarak dan arah tertentu. Hasil ekstraksi fitur dilakukan pengukuran jarak kemiripan menggunakan metode Euclidean Distance. Dari uji coba aplikasi menggunakan pengukuran kemiripan Euclidean Distance dengan nilai threshold=7 diperoleh akurasi presisi sebesar  61%  pada data pelatihan 168 dan data uji coba 32 dengan 10 citra yang ditampilkan. &#39;]}
2022-06-29 22:20:59 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100120&gt;

{&#39;judul&#39;: [&#39;PEMANFAATAN TOGAF ADM UNTUK PERANCANGAN SISTEM INFORMASI DINAS PERINDUSTRIAN &amp; PERDAGANGAN SEBAGAI SUB SISTEM ARSITEKTUR E-GOVERNMENT KABUPATEN BANGKALAN&#39;], &#39;penulis&#39;: [&#39;Penulis : Norman&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : M. Kautsar Sophan, S.Kom., M. MT.&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Yeni Kustiyahningsih S.Kom., M.Kom.&#39;], &#39;abstrak&#39;: [&#39;Penyusunan Sistem Informasi Dinas Perindustrian &amp; Perdagangan (DISPERINDAG) Kabupaten Bangkalan dibuat untuk meningkatkan kualitas pelayanan dan membantu proses kinerja dari dinas tersebut. Salah satu faktor pendorong pemanfaatan sistem informasi yang lebih baik adalah semakin meningkatnya kebutuhan fungsi pelayanan yang dijalankan. Tujuan dari penerapan Arsitektur Enterprise adalah menciptakan keselarasan antara bisnis dan teknologi informasi bagi kebutuhan instansi, penerapan arsitektur enterprise tidak terlepas dari bagaimana sebuah instansi merencanakan dan merancang arsitektur enterprise tersebut. TOGAF ADM merupakan metodologi yang lengkap, banyak instansi yang tidak memahami secara jelas tentang tahapan – tahapan dari metodologi tersebut diterjemahkan ke dalam aktivitas perancangan Arsitektur Enterprise. Tahapan dalam perancangan Arsitektur Enterprise sangatlah penting dan akan berlanjut pada tahapan berikutnya yaitu rencana implementasi. TOGAF ADM memiliki empat komponen utama: arsitektur bisnis, arsitektur data, arsitektur teknologi dan arsitektur aplikasi. Pada intinya TOGAF digunakan untuk membuat Arsitektur Enterprise dari semua aspek tersebut yang menghasilkan model dan kerangka dasar dalam mengembangkan sistem informasi yang terintegrasi untuk mendukung kebutuhan Dinas Perindustrian &amp; Perdagangan sesuai dengan Peraturan Bupati Bangkalan Nomor 38 Tahun 2010 Tentang Uraian Tugas Jabatan Struktural pada Dinas Perindustrian dan Perdagangan.&#39;]}
2022-06-29 22:20:59 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100036&gt;

{&#39;judul&#39;: [&#39;ONTOLOGY SEMANTIC WEB UNTUK PENCARIAN TUGAS AKHIR PADA SISTEM INFORMASI TUGAS AKHIR(SIMTAK)&#39;], &#39;penulis&#39;: [&#39;Penulis : Daniyar Bagus Prasetya&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Firdaus Solihin S.kom,.M.kom&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Kurniawan Eka P. S.kom,.M.sc&#39;], &#39;abstrak&#39;: [&#39;Kebutuhan pencarian data pada internet yang cepat dan tepat saat ini menjadi faktor penting para pengguna layanan internet. Sistem Informasi Tugas Akhir (SIMTAK) yang digunakan di Fakultas Teknik Universitas Trunojoyo Madura juga membutuhkan pencarian data yang tepat dan cepat berdasarkan konteks. Sistem pencarian yang dipakai saat ini adalah pencarian database dimana masih belum mampu memberikan hasil pencarian yang sesuai dengan konteks atau keywords yang diinputkan. Untuk memiliki kebenaran dalam sistem kecerdasan, pengetahuan perlu ditangkap, diproses, digunakan kembali, dan disampaikan. Ontologi mendukung semua tugas ini. Ontologi adalah spesifikasi dari konseptualisasi. Semantik web adalah sebuah abstrak representasi pada World Wide Web (WWW) yang berbasiskan pada sebuah standar yang didefinisikan menggunakan Resource Description Framework (RDF) dan Ontology Web Language (OWL) ide dasarnya adalah untuk membawa web memiliki definisi dan link data sehingga dapat digunakan lebih efektif untuk mencari, otomasi, integrasi dan reuse informasi pada berbagai aplikasi. Semantik web didefinisikan sebagai sekumpulan teknologi, dimana memungkinkan komputer memahami arti dari sebuah informasi berdasarkan metadata, yaitu informasi mengenai isi informasi seperti judul, pengarang, modifikasi tanggal pada halaman web, dan hak cipta pada halaman web. Dengan menggunakan semantik web, pencarian tugas akhir ini mampu memberikan hasil berdasarkan persamaan makna kata pada keyword yang diinputkan oleh user.\r\nKata Kunci : Mesin pencari, Semantic web, Tugas akhir.\r\nABSTRACT&#39;]}
2022-06-29 22:20:59 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100143&gt; (referer: None)
2022-06-29 22:20:59 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100143&gt;

{&#39;judul&#39;: [&#39;APLIKASI METODE FUZZY ANALYTIC NETWORK PROCESS (FANP) UNTUK MENDUKUNG KEPUTUSAN PROSES PROMOSI JABATAN DI PT. SURYA MADISTRINDO PAMEKASAN&#39;], &#39;penulis&#39;: [&#39;Penulis : Robiatul Adawiyah, S.Kom&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Diana Rahmawati, S.T, M.T&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Budi Dwi Satoto, S.T, M.Kom&#39;], &#39;abstrak&#39;: [&#39;Perusahaan pemerintah maupun swasta mempunyai tujuan yang harus dicapai. Pencapaian tujuan perusahaan dapat dilakukan dengan pemanfaatan sumber daya yang dimiliki secara optimal, salah satu sumber daya tersebut adalah sumber daya manusia yang dimiliki oleh perusahaan. Sesuai dengan peraturan yang telah ditetapkan PT. Surya Madistrindo Pamekasan dalam melakukan proses promosi jabatan, maka diperlukan kriteria-kriteria seperti aspek kapasitas intelektual, aspek sikap kerja, dan aspek perilaku yang masing-masing mempunyai sub kriteria tersendiri. Metode yang digunakan adalah metode Fuzzy Analytic Network Process (FANP). Metode FANP sendiri digunakan untuk mencari bobot prioritas kepentingan dari seluruh kriteria dan sub kriteria yang telah ditetapkan dan sebagai proses perangkingan atas bobot kriteria masing-masing data karyawan. Pembobotan diperoleh dari hasil kuesioner yang dilakukan oleh pimpinan perusahaan. Proses perangkingan dilakukan dengan cara mengalikan nilai bobot dari kriteria ke tiap-tiap sub kriteria sehingga mampu menyeleksi karyawan yang berhak menduduki jabatan yang tersedia berdasarkan kriteria-kriteria yang ditentukan. Dari hasil uji coba dalam menyelesaikan studi kasus proses promosi jabatan karyawan menghasilkan nilai akurasi sebesar 80%.\r\n\r\n\r\nKata kunci \t: \tSistem Pendukung Keputusan, Promosi Jabatan,  Fuzzy Analytic Network Process (FANP)\r\n&#39;]}
2022-06-29 22:20:59 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100050&gt; (referer: None)
2022-06-29 22:20:59 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100037&gt; (referer: None)
2022-06-29 22:20:59 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100079&gt; (referer: None)
2022-06-29 22:20:59 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100050&gt;

{&#39;judul&#39;: [&#39;DETEKSI COREPOINT SIDIK JARI MENGGUNAKAN METODE GEOMETRY OF REGION TECHNIQUE (GR)&#39;], &#39;penulis&#39;: [&#39;Penulis : Erwina Safitri&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Dr. Indah Agustien, S.Kom., M.Kom&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Fitri Damayanti, S.Kom., M.Kom&#39;], &#39;abstrak&#39;: [&#39;Sidik jari adalah salah satu karakteristik fisik manusia yang saat ini banyak digunakan untuk identifikasi manusia, karena sidik jari mempunyai karakteristik yang tidak dapat berubah kecuali jika luka atau rusak akibat kecelakaan. Sidik jari sangat diperlukan untuk berbagai kasus tindak kriminal, seperti pencurian, kecurangan administrasi. Sehingga adanya proses pendeteksian sidik jari dapat memudahkan pihak-pihak yang berwajib untuk menangani beberapa kasus tersebut. Proses pendeteksian ini di lakukan dalam program komputer dengan melakukan beberapa tahap perhitungan. Penentuan titik tengah atau yang biasa di kenal dengan Corepoint adalah sebuah proses awal yang sangat berperan penting dalam proses identifikasi manusia. Terdapat dua cara untuk menentukan Corepoint atau titik tengah sidik jari yaitu secara manual dan otomatis. Secara manual dapat di lakukan dengan kasat mata. sedangkan secara otomatis dapat di tentukan dengan menggunakan suatu sistem. Pada Tugas Akhir ini untuk menentukan Corepoint sidik jari secara otomatis digunakan metode Geometry Of Region Technique (GR).Citra yang digunakan pada Tugas Akhir diperoleh dari “database FVC-2002 fingerprint-bitmaps”. Hasil uji coba sistem yang terbaik untuk deteksi Corepoint sidik jari menggunakan metode Geometry Of Region Technique (GR) dengan M0=50 dan V0=50 pada proses normalisasi dan menggunakan ukuran blok 3 x 3 pixel. Hasil akurasi sistem yang didapatkan sebesar 70%.\r\nKata Kunci : Sidik jari, Corepoint, Geometry Of Region Technique (GR), Normalisasi&#39;]}
2022-06-29 22:20:59 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100037&gt;

{&#39;judul&#39;: [&#39;SISTEM PENDUKUNG KEPUTUSAN REKOMENDASI MENU DIET BAGI PASIEN RAWAT INAP MENGGUNAKAN METODE HARRIS BENEDICT DAN EUCLIDEAN (Studi Kasus : RSUD Dr. H. Moh. Anwar Sumenep)\r\n&#39;], &#39;penulis&#39;: [&#39;Penulis : Desy Mariana S. Kom&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Haryanto ST, MT&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Firli Irhamni ST, M. Kom&#39;], &#39;abstrak&#39;: [&#39;Pelayanan makanan bagi pasien rawat inap di Rumah Sakit mempunyai tujuan untuk memberikan menu diet yang sesuai dengan syarat gizi minimal dan sesuai dengan penyakit yang diderita pasien. \r\nSampai saat ini menu yang disediakan pihak rumah sakit kurang memperhatikan kebutuhan kalori pasiennya per individu. Sehingga mengakibatkan penyediaan makanan kepada pasien tidak sesuai dengan kebutuhan kalori perhari dari pasien. Oleh karena itu dibuatlah sistem pendukung keputusan untuk rekomendasi menu diet pasien sebagai alat bantu dalam penyediaan menu makanan bagi pasien\r\nMetode yang digunakan yaitu metode Harris Benedict untuk perhitungan total kalori pasien dan metode Euclidean untuk perankingannya, maka diharapkan aplikasi sistem pendukung keputusan yang dibuat ini mampu untuk merekomendasikan menu diet kepada pasien beserta penjelasan mengenai kebutuhan kalori perhari untuk asupan makanan perhari dan makanan yang harus dibatasi.\r\n\r\nKata kunci :  Sistem Pendukung Keputusan, Harris Benedict dan Euclidean\r\n&#39;]}
2022-06-29 22:20:59 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100079&gt;

{&#39;judul&#39;: [&#39;RANCANG BANGUN APLIKASI PEMILIHAN TEKNIK REKAYASA KEBUTUHAN MENGGUNAKAN METODE SELF ORGANIZING MAP BERBASIS EUCLIDEAN DISTANCE DAN CANBERRA DISTANCE MATRIX&#39;], &#39;penulis&#39;: [&#39;Penulis : Lia Fransiska&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Firli Irhamni S.T, M.Kom&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Budi Dwi Satoto S.T, M.Kom&#39;], &#39;abstrak&#39;: [&#39;Penyusunan Sistem Pendukung Keputusan pemilihan teknik rekayasa kebutuhan dibuat untuk membantu pengembang perangkat lunak dalam membangun sebuah proyek perangkat lunak. Pemilihan teknik rekayasa kebutuhan umumnya berdasarkan pada pilihan system dan analis yang bersangkutan daripada berdasarkan karakteristik teknik rekayasa kebutuhan yang sesuai pada proyek perangkat lunak tersebut. Untuk dapat menghasilkan perangkat lunak yang baik maka proses evaluasi dan pemilihan teknik rekayasa kebutuhan merupakan salah satu tahap yang sangat penting dalam sebuah proyek pengembangan perangkat lunak.\r\n\tDidalam SPK ini dilakukan proses pemilihan antara teknik rekayasa kebutuhan dan kriteria atribut project yang diinginkan oleh pengembang perangkat lunak. Selanjutnya dilakukan proses clustering menggunakan metode Self Organizing Map (SOM). Parameter yang digunakan dalam adalah distance matrix karena paling tepat digunakan untuk menangani data multi dimensional. Euclidean dan Canberra adalah jenis distance matrix yang lazim digunakan karena tingkat akurasinya yang baik untuk menangani kasus data riil.\r\nHasil akhir yang diperoleh yaitu membandingkan hasil clustering menggunakan metode SOM berbasis Euclidean Distance dan Canberra Distance matrix. Sehingga menghasilkan teknik rekayasa kebutuhan yang efisien, obyektif dan sesuai dengan karakteristik proyek perangkat lunak.\r\nKata Kunci : Sistem Pendukung Keputusan, Teknik Rekayasa Kebutuhan, Clustering, Self Organizing Map, Canberra Distance matrix&#39;]}
2022-06-29 22:21:00 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/080411100086&gt; (referer: None)
2022-06-29 22:21:00 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/080411100086&gt;

{&#39;judul&#39;: [&#39;SISTEM PENDUKUNG KEPUTUSAN PEMILIHAN KARYAWAN BERPRESTASI DENGAN INTEGRASI FAHP dan ELECTRE II&#39;], &#39;penulis&#39;: [&#39;Penulis : Catur Ngesti Waluyo&#39;], &#39;pembimbing_1&#39;: [&quot;Dosen Pembimbing I : Mula&#39;ab,S.Si.,M.Kom&quot;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Riza Alfita, S.T., M.T&#39;], &#39;abstrak&#39;: [&#39;Sumber daya manusia mutlak dibutuhkan untuk kemajuan suatu perusahaan guna menjadikan perusahaan itu menjadi perusahaan yang maju dan tidak kalah bersaing dengan perusahaan lainnya. Dalam hal ini maka dibuatlah Sistem Pendukung keputusan (SPK) pemilihan karyawan berprestasi untuk mencari karyawan berprestasi. Sistem Pendukung keputusan (SPK) ini menggunakan FAHP dan ELECTRE II. Metode FAHP merupakan metode yang cukup obyektif untuk proses penilaian berdasarkan hirarki kriteria yang digabungkan dengan konsep fuzzy sesuai kriteria penilaian kinerja karyawan perusahaan. Setelah mendapat bobot dilakukan proses selanjutnya dengan menggunakan metode ELECTRE II hingga mendapat karyawan berprestasi. Untuk menjaga bahwa penilaian ini tidak berpihak kepada salah satu karyawan dan bebas intervensi dari karyawan maka perusahaan menggunakan pihak luar yang independen dan profesional untuk melakukan penilaian terhadap karyawan. Hasil penilaian dari pihak luar yang berupa angka-angka kemudian oleh departemen sdm dilakukan penjumlahan nilai komulatif kriteria untuk mendapat karyawan terbaik tanpa ada prioritas kriteria yang lebih penting. Dengan menggunakan metode FAHP dan ELECTREII hasil keluaran mendekati keakuratan dengan hasil yang diperoleh dari areal manager di banding dengan hitung manual perusahaan tanpa memperhatikan bobot kepentingan.&#39;]}
2022-06-29 22:21:00 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/080411100125&gt; (referer: None)
2022-06-29 22:21:00 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/080411100052&gt; (referer: None)
2022-06-29 22:21:00 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/060411100818&gt; (referer: None)
2022-06-29 22:21:00 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/080411100125&gt;

{&#39;judul&#39;: [&#39;PENGENALAN TELAPAK TANGAN MENGGUNAKAN METODE NAÏVE BAYES BERBASIS REDUKSI DIMENSI  PRINCIPAL COMPONENT ANALYSIS (PCA)&#39;], &#39;penulis&#39;: [&#39;Penulis : Daril Ulumiyah&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Mulaab, S.Si., M.Kom.&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Rima Tri Wahyuningrum, ST.,MT.&#39;], &#39;abstrak&#39;: [&#39;Teknologi biometrik saat ini mengalami perkembangan sangat pesat dan sudah lazim diterapkan pada berbagai bidang aplikasi. Proses pengenalan telapak tangan telah diteliti selama lebih dari 10 tahun.  Telapak tangan merupakan biometrika yang masih relatif baru. Telapak tangan memiliki beberapa karakteristik yang unik berupa garis telapak tangan dan bersifat stabil. Setiap orang mempunyai garis telapak tangan yang berbeda meskipun orang itu kembar. Keunikan dan kestabilan dari garis telapak tangan pada telapak tangan merupakan fitur handal setiap telapak tangan untuk digunakan pada sistem pengenalan. Dalam penelitian ini, proses pengenalan telapak tangan menggunakan metode Naive Bayes sebagai proses classifier dan  reduksi dimensinya menggunakan Principal Component Analysis (PCA). Sistem diuji coba menggunakan 100 citra telapak tangan dari 10 orang, setiap orang terdiri dari 10 sampel telapak tangan. Hasil pengujian rata-rata memperoleh persentase keberhasilan sebesar 51,45%.&#39;]}
2022-06-29 22:21:00 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/060411100818&gt;

{&#39;judul&#39;: [&#39;APLIKASI CITRA MOSAIC PANORAMIC MENGGUNAKAN METODE SIFT (SCALE INVARIANT FEATURE TRANSFORM)&#39;], &#39;penulis&#39;: [&#39;Penulis : Gendra Budiarti&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Eza Rahmanita, ST, MT&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Meidya Koeshardianto, S.Si, MT&#39;], &#39;abstrak&#39;: [&#39;Sebuah citra banyak diterapkan dalam berbagai aspek kehidupan, misalnya dalam bidang kedokteran untuk mengetahui bagian dalam tubuh manusia atau mendeteksi penyakit, dalam bidang geologi untuk memetakan suatu wilayah tertentu, dan lain sebagainya. Oleh karena itu dibutuhkan suatu tampilan citra yang dapat merepresentasikan suatu obyek. Namun batasan luas citra sering menjadi kendala dalam penerapan fungsi maupun manfaat citra itu sendiri. Untuk itu diperlukan aplikasi penggabungan citra atau mosaic panoramic yang dapat memperluas tampilan citra, sehingga dapat lebih bermanfaat untuk memberikan informasi suatu obyek tertentu. Pada penelitian ini menggunakan metode Scale Invariant Feature Transform (SIFT) untuk pendeteksian keypoint. Jumlah keypoint dapat berubah berdasarkan nilai threshold yang ditentukan. Dari 20 pasang citra yang diteliti, nilai threshold 0.1 pada 12 citra masukan jumlah keypoint yang berkesesuaian bernilai 0, sehingga tidak dapat dilakukan proses mosaic panoramic. Pada nilai threshold 0.6 jumlah keypoint yang berkesesuaian bernilai sedang dan dapat menghasilkan citra hasil mosaic panoramic. Sedangkan pada nilai threshold 0.9 jumlah keypoint yang berkesesuaian pada 14 pasang citra masukan atau 70% dari jumlah citra masukan semakin banyak ditemukan, sehingga  dapat dilakukan proses mosaic panoramic dan menghasilkan citra hasil mosaic panoramic yang lebih baik.\r\n\r\nKata Kunci:  Mosaic Panoramic, SIFT (Scale Invariant Feature Transform), Keypoint\r\n&#39;]}
2022-06-29 22:21:00 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/080411100052&gt;

{&#39;judul&#39;: [&#39;PENGELOMPOKAN KUALITAS KELAS PADA SISWA MENGGUNAKAN INDEKS DAVIES-BOULDIN SOM (SELF ORGANIZING MAP)&#39;], &#39;penulis&#39;: [&#39;Penulis : Hamiyah&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Bain Khusnul K,ST.,M.Kom&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Firli Irhamni, ST, M. Kom&#39;], &#39;abstrak&#39;: [&#39;ABSTRAK\r\nData yang terdapat pada SMA Wachid Hasyim 2 Taman-Sepanjang merupakan data siswa yang masih mentah sehingga data tersebut perlu diolah. Pengolahan data dengan mengelompokan (Clustering) data-data tersebut memiliki beragam metode salah satunya adalah SOM (Self Organizing Map). Untuk menvalidasi data setelah Penggunaan distance matrix digunakan IDB (Indeks Davies-Bouldin). IDB dalam SOM bertujuan untuk meningkatkan akurasi validasi hasil analisa data. Pada akhirnya penganalisaan data dengan studi kasus SMA Wachid Hasyim 2 Taman-Sepanjang ini bertujuan untuk mengetahui tingkat kemiripan siswa dalam satu kelompok (per kelas). Metode SOM mampu mengelompokan data yang berdekatan untuk dicari kemiripannya berdasarkan pola. Kemiripan data pada pengelompokan siswa yang dijadikan tiga cluster dengan learning rate 0.6 serta epoch 10, 20, 30  dengan MSE terkecil = 41.42 di epoch 30 pada 245 data training. Sedangkan yang dijadikan tiga sampai dengan sembilan Cluster dengan learning rate 0.6 serta epoch 10, 20, 30 dengan MSE terkecil = 25.04 di epoch 20 pada cluster  ke-4 dengan  245 data training. Nilai terkecil pada pemvalidasian Cluster dengan IDB menggunakan tiga sampai dengan sembilan Cluster pada 245 data training berada pada  cluster ke-9 dengan nilai IDB = 37.44  dan hasilnya  kurang akurat karena kelas yang terbentuk hanya dua kelompok.\r\n\r\n\r\nKata kunci:  Clustering, SOM, Eucledian Distance, IDB, SMA Wachid Hasyim 2 Taman-Sepanjang\r\n&#39;]}
2022-06-29 22:21:00 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/080411100029&gt; (referer: None)
2022-06-29 22:21:00 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File &quot;C:\Python310\lib\site-packages\scrapy\core\engine.py&quot;, line 150, in _next_request
    request = next(self.slot.start_requests)
  File &quot;D:\Kuliah\Semester 6\Penambangan dan Pencarian Web\jupyter-book\PPW\crawlproject\crawlproject\spiders\detail.py&quot;, line 69, in start_requests
    yield scrapy.Request(url=url, callback=self.parse)
  File &quot;C:\Python310\lib\site-packages\scrapy\http\request\__init__.py&quot;, line 60, in __init__
    self._set_url(url)
  File &quot;C:\Python310\lib\site-packages\scrapy\http\request\__init__.py&quot;, line 108, in _set_url
    raise ValueError(f&#39;Missing scheme in request url: {self._url}&#39;)
ValueError: Missing scheme in request url: link
2022-06-29 22:21:00 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/080411100029&gt;

{&#39;judul&#39;: [&#39;Implementasi Sistem Pakar Pada Pengambilan Keputusan Penentuan Tindakan Medis di Poli Mata Berbasis Web&#39;], &#39;penulis&#39;: [&#39;Penulis : Rizky Maulidya&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Fika Hastarita Rachman S.T., M.Eng&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Firli Irhamni S.T., M.Kom&#39;], &#39;abstrak&#39;: [&#39;Diagnosa penyakit mata dengan sistem informasi yang baik merupakan inti permasalahan pada penelitian ini. Diketahui pada studi kasus ini, dokter sebagai seorang pakar memiliki keterbatasan waktu dalam melayani pasien selama 24 jam, bahkan pada hari-hari selanjutnya. Dokter hanya bekerja tiga hari dalam satu minggu, dan 6 jam pada tiap kali melakukan pelayanan. Adanya asisten dokter juga belum dapat membantu pelayanan ini bekerja denga maksimal. Hal ini lah yang menjadi kurang maksimalnya peranan dokter bagi pasien. Terbatasnya keberadaaan dokter sebagai pakar dan minimnya waktu pelayanan dari dokter pada pasien nya serta minimnya pengetahuan seseorang terhadap gejala atas sakit yang dirasakan, sangat mendukung terdapatnya sistem yang mampu memberikan diagnosa dan solusi mengenai gejala yang diketahui. Berdasarkan hal tersebut, penelitian ini bertujuan untuk membuat aplikasi sistem pakar  berbasis web, yang  dapat mendiagnosa gejala penyakit pada mata. Metode yang digunakan dalam pengembangan aplikasi adalah Fuzzy Mamdani dengan Inferensi Forward Chainning. Input yang dibutuhkan pada sistem ini adalah data jenis gejala dan gejala umum yang diketahui, sedangkan output adalah nilai tingkat keparahan penyakit yang nantinya mengarah pada solusi dari tiap kasus. Dari hasil uji coba sistem yang dilakukan oleh dokter diperoleh nilai keakuratan sebesar 80% dari 10 kasus yang dilakukan. \r\n\r\nKata kunci : Metode Fuzzy Mamdani, forward chaining , diagnosa penyakit mata.\r\n&#39;]}
2022-06-29 22:21:00 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100029&gt; (referer: None)
2022-06-29 22:21:00 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/060411100824&gt; (referer: None)
2022-06-29 22:21:01 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/060411100772&gt; (referer: None)
2022-06-29 22:21:01 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100029&gt;

{&#39;judul&#39;: [&#39;RANCANG BANGUN APLIKASI INTRUSION PREVENTION SYSTEM PADA JARINGAN BERBASIS PROTOKOL TCP/IP MENGGUNAKAN SNORT DAN IPTABLES&#39;], &#39;penulis&#39;: [&#39;Penulis : BAHRUL ULUM&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Meidya Koeshardianto, S.Si., M.T&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Eza Rahmanita, S.T., M.T&#39;], &#39;abstrak&#39;: [&#39;Dalam setiap perusahaan tentunya memiliki data penting berkaitan dengan kegiatan bisnis mereka yang perlu dijaga dan diamankan dari orang yang tidak berhak mengaksesnya. Seringkali  muncul aksi ilegal yang mencoba merusak server bahkan sampai mencuri data perusahaan bisa mengakibatkan kesalahan fatal terhadap kelancaran kegiatan bisnis perusahaan disebabkan data yang tidak valid lagi. Menyikapi masalah tersebut, maka diperlukannya sistem monitoring keamanan yang mampu mengamankan server dari tindakan penyusupan. Intrusion Prevention System (IPS) merupakan solusi yang mampu memberikan keamanan pada jaringan server dari tindakan penyusupan. IPS ini mengembangkan Snort sebagai fungsi pendeteksi yang dikombinasikan dengan IPTables Firewall sebagai pencegah adanya penyusupan. IPS ini juga dilengkapi dengan user interface BASE (Basic Analysis and Security Engine)  dan manajemen rule sehingga memudahkan admin untuk memonitor sistem keamanan dari tindakan penyusupan ke jaringan server. Snort akan membuat alert ketika terdeteksi adanya serangan yang disimpan dalam log Snort dan memerintahkan IPTables untuk melakukan drop terhadap alamat penyerang. Kemudian detail serangan bisa dilihat pada tampilan user interface BASE. Dari hasil pengujian, didapatkan bahwa Snort dan IPTables telah bekerja dengan baik menjadi IPS yang mampu memberikan respon secara cepat ketika terdeteksi adanya serangan. Waktu tanggap rata-rata kurang dari 5 detik, dari awal serangan sampai terdeteksinya alert.&#39;]}
2022-06-29 22:21:01 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/060411100824&gt;

{&#39;judul&#39;: [&#39;APLIKASI CITRA MOSAIK PANORAMIK MENGGUNAKAN METODE WATERSHED&#39;], &#39;penulis&#39;: [&#39;Penulis : Sri Rahma Puspa Sari&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Eza Rahmanita, S.T.,M.T.&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Meidya Koeshardianto, S.Si.,M.T.&#39;], &#39;abstrak&#39;: [&#39;Citra digital banyak dimanfaatkan dalam berbagai aspek kehidupan,oleh karena itu membutuhkan tampilan citra yang yang dapat merepresentasikan objek yang terdapat dalam citra tersebut. Salah satu permasalahan yang ada saat melakukan pengambilan gambar (citra) adalah kemampuan untuk mengambil gambar yang sangat luas sehingga gambar harus diambil beberapa kali yang menyebabkan gambar atau objeknya menjadi terpisah-pisah. Untuk mengatasi permasalahan ini diperlukan proses penggabungan citra. Dan dalam penelitian ini akan digunakan metode Watershed. Dalam metode ini terlebih dahulu ditentukan titik korespondensi pada masing-masing citra kandidat, kemudian daerah hasil korespondensi tersebut akan disegmen menggunkan metode Watershed dan hasil segmentasinya digunakan untuk mencari Region cut sebagai acuan penggabungan citra. Proses penggabungan citra ini dsebut dengan mosaic panoramik. Hasil dari penelitian ini menunjukkan citra panorama yang ideal dapat dperoleh dengan menggunakan citra masukan yang mempunyai kesamaan obyek dan titik korespondensi dipilih pada obyek yang sama diantara dua citra masukan tersebut.\r\n\r\nKata kunci :Citra Panorama, MosaikPanoramik, Metode watershed\r\n&#39;]}
2022-06-29 22:21:01 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/060411100772&gt;

{&#39;judul&#39;: [&#39;ANALISA VALIDITAS PENERIMA BEASISWA MENGGUNAKAN METODE ANALYTIC NETWORK PROCESS DAN TOPSIS&#39;], &#39;penulis&#39;: [&#39;Penulis : Hilmi Fairuz Abadi&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Bain Khusnul K., S.T., M.Kom.&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Firli Irhamni, S.T., M.Kom.&#39;], &#39;abstrak&#39;: [&#39;Beasiswa adalah pemberian berupa bantuan keuangan yang diberikan kepada perorangan yang bertujuan untuk digunakan demi keberlangsungan pendidikan yang ditempuh. Program beasiswa diadakan untuk meringankan beban mahasiswa dalam menempuh masa studi kuliah khususnya dalam masalah biaya. Fakultas Teknik Universitas Trunojoyo memiliki program beasiswa yang harus diberikan kepada yang berhak menerima. Diantaranya Beasiswa Bantuan Belajar Mahasiswa (BBM), Beasiwa Peningkatan Prestasi Akademik (PPA) dan setiap jenis beasiswa memiliki kriteria atau faktor bobot yang berbeda. Tetapi dalam melakukan seleksi beasiswa tentu akan mengalami kesulitan karena banyaknya pemohon, banyaknya kriteria dan masih menggunakan cara manual yang mengakibatkan kurang efektifnya keputusan. Untuk membantu dalam menetapkan seseorang yang layak menerima beasiswa maka dibutuhkan sistem pendukung keputusan. Metode yang digunakan dalam penelitian ini adalah Analytic Network Process (ANP) dan Technique Order Preference by Similarity To Ideal Solution (TOPSIS). Pada penelitian ini akan diangkat suatu kasus yaitu menganalisa validitas alternatif terbaik penerima beasiswa berdasarkan kriteria-kriteria yang telah ditentukan dengan menggunakan metode ANP kemudian dicari solusi pengurutan dengan menggunakan metode TOPSIS. Berdasarkan hasil uji coba sistem, terdapat perbedaan selisih hasil rekomendasi dari sistem terhadap data aktual pemenang beasiswa PPA jurusan informatika, yaitu 78,57%. Sedangkan selisih hasil rekomendasi dari sistem terhadap data aktual pemenang beasiswa BBM jurusan informatika, yaitu 80,95%.\r\n\r\nKata kunci: ANP, TOPSIS, MCDM, pengambilan keputusan multi kriteria, seleksi beasiswa.\r\n&#39;]}
2022-06-29 22:21:01 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/080411100001&gt; (referer: None)
2022-06-29 22:21:01 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/080411100001&gt;

{&#39;judul&#39;: [&#39;SISTEM PERAMALAN PENJUALAN JANGKA PENDEK SPARE PART SEPEDA MOTOR MENGGUNAKAN NEURAL NETWORK\r\n(Studi Kasus : Suzuki Kemayoran Bangkalan)&#39;], &#39;penulis&#39;: [&#39;Penulis : Ana Qaimah L.M.D.R&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Mula’ab, S.Si, M.Kom&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Fika Hastarita R.,ST, M.Eng&#39;], &#39;abstrak&#39;: [&#39;Spare part merupakan salah satu bagian penting dalam pengoperasian mesin pada sepeda motor. Peningkatan jumlah penjualan spare part yang tidak terduga saat proses tune-up menyebabkan kesulitan dalam pelayanan yang terbaik kepada konsumen. Demikian juga sebaliknya, apabila terjadi penurunan jumlah penjualan spare part, maka akan menyebabkan penumpukan spare part di gudang. Oleh karena itu diperlukan sistem peramalan yang mampu meramalkan penjualan spare part pada periode berikutnya. Sistem peramalan ini menggunakan metode Jaringan Syaraf Tiruan algoritma Propagasi Balik dengan momentum untuk meramalkan jumlah penjualan spare part  pada bulan berikutnya. Data yang telah tersimpan dihitung menggunakan epoh dan learning rate yang berbeda. Dari hasil uji coba system, maka dapat disimpulkan bahwa  dengan menggunakan semua data sebagai data training dan menggunakan learning rate 3.5 dan dengan epoh 200 akan menghasilkan tingkat kesalahan 0.0622716.&#39;]}
2022-06-29 22:21:01 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/080411100012&gt; (referer: None)
2022-06-29 22:21:01 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/060411100801&gt; (referer: None)
2022-06-29 22:21:01 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100170&gt; (referer: None)
2022-06-29 22:21:01 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/080411100012&gt;

{&#39;judul&#39;: [&#39;APLIKASI DAN DESAIN MODEL DECISION AID PELANGGAN\r\nPADA E-COMMERCE TOKO BATIK TULIS MADURA\r\n&#39;], &#39;penulis&#39;: [&#39;Penulis : Ardiyanto Setiawan&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Moch. Kautsar Sophan, S.Kom., M.MT.&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Yeni Kustiyah Ningsih, S.Kom., M.Kom.&#39;], &#39;abstrak&#39;: [&#39;Toko Batik Tulis Madura merupakan salah satu toko yang telah beroperasi sejak tahun 2011 dengan\r\nmenggunakan website e-commerce. Walau telah menggunakan model e-commerce, website tersebut memiliki\r\nkekurangan yaitu belum ada fitur rekomndasi untuk memudahkan konsumen mencari barang yang ingin\r\ndibelinya. Penelitian ini bertujuan membuat rekomendasi dengan decision aid untuk membantu pelanggan\r\ndalam memilih produk di website Toko Batik Tulis Madura. Teknik pengumpulan analis data terdiri dari\r\nStudi Literatur yang berhubungan dengan decision aid dan multi criteria, Observasi dilakukan terhadap\r\nwebsite Toko Batik Tulis Madura dan Interview dilakukan kepada pemilik website Toko Batik Tulis Madura.\r\nPembuatan implementasi pada Penelitian ini menggunakan model waterfall. Jenis decision aid yang akan\r\ndiimplementasikan adalah Multi Criteria Filtering. Metode pembobotan yang digunakan pada Multi Criteria\r\nFiltering yaitu Decision Matrix. Hasil ujicoba dengan jumlah sample percobaan sebanyak 50 kali data\r\nperconbaan pencarian, presentase akurasi adalah 94% dan error adalah 6%. Hasil uji kelayakan dari beberapa\r\nkuisoner dihasilkan bahwa performa yang dimiliki tool ini cukup baik dan tool ini layak untuk diintegrasikan\r\nserta digunakan dalam website e-commerce.\r\n\r\nKata Kunci: Decision, Aid, Multi, Criteria, Filtering&#39;]}
2022-06-29 22:21:01 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/060411100801&gt;

{&#39;judul&#39;: [&#39;PENGEMBANGAN MESIN PENCARIAN ANTIPLAGIASI PADA \r\nSIM JURNAL MAHASISWA MENGGUNAKAN ALGORITMA \r\nWINNOWING FUZZY K-MEANS&#39;], &#39;penulis&#39;: [&#39;Penulis : ilham wibisono aziz&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Hermawan S.T.,M.Kom&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Andharini Dwi Cahyani S.Kom.,M.Kom&#39;], &#39;abstrak&#39;: [&#39;ABSTRAK\r\nPenjiplakan merupakan masalah yang sering muncul dan semakin berkembang terutama dalam bidang pendidikan. Banyak karya tulis yang sebagian bahkan seluruh isinya dibuat dengan menjiplak dari karya tulis orang lain. Untuk mengatasi masalah tersebut, salah satunya solusinya adalah dengan dibuatnya aplikasi yang dapat mengelompokan dokumen dan mendeteksi penjiplakan pada dokumen tersebut. Pada tugas akhir ini dibuat aplikasi yang dapat mendeteksi penjiplakan antar dokumen yaitu dengan membandingkan antar dokumen. Dalam melakukan pendeteksian penjiplakan dokumen digunakan algoritma Winnowing. Algoritma winnowing ini berfungsi untuk melakukan proses dokumen fingerprint, yaitu dengan merubah teks menjadi sekumpulan nilai - nilai hash. Nilai hash ini yang akan digunakan untuk mendeteksi tingkat kesamaan antar dokumen. Dalam hal pengelompokan dokumen dipergunakan algoritma fuzzy k-means. Dari hasil uji coba aplikasi ini dapat diambil kesimpulan bahwa semakin besar nilai n-gram, basis, dan window maka semakin kecil hasil prosentase kemiripan antar dokumen yaitu dengan menghasilkan sebesar 4.17%, dan sebaliknya semakin kecil nilai n-gram, basis, dan window maka semakin besar  prosentase kemiripan antar dokumen yaitu dengan menghasilkan prosentase 98.49%. Pada perhitungan nilai f-measure dipengaruhi oleh keakuratan data yang diproses.\r\nKata Kunci : deteksi penjiplakan, cluster, f-measure&#39;]}
2022-06-29 22:21:01 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100170&gt;

{&#39;judul&#39;: [&#39;Segmentasi Parasit Malaria Dalam Sel Darah Menggunakan Operasi Morfologi Dan Transformasi Watershed&#39;], &#39;penulis&#39;: [&#39;Penulis : Yenni Rahmawati&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Rima Tri Wahyuningrum, S.T.,M.T.&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Fitri Damayanti, S.Kom., M.Kom&#39;], &#39;abstrak&#39;: [&#39;Malaria disebabkan oleh intraseluler parasit bersel tunggal yang dimiliki genus Plasmodium yang menginfeksi manusia dengan memasuki aliran darah. Dampak malaria secara geografis memiliki tingkat  transmisi tertinggi di daerah tropis dan subtropics, yaitu di negara-negara yang memiliki tingkat pertumbuhan penduduk yang besar (termasuk Indonesia). Pendeteksian parasit malaria dapat dilakukan mencari titik kromatin. Bila tidak ada titik kromatin pada sel darah merah  maka sel darah merah tersebut di anggap sebagai sel darah merah sehat. Pendeteksian titik kromatin secara manual akan memerlukan waktu yang lama. Proses segmentasi diharapkan sebagai langkah pertama untuk memudahkan pendeteksian titik kromatin karena segmentasi merupakan  salah  satu  faktor yang sangat penting dalam analisis suatu gambar. Penelitian ini melakukan segmentasi sel darah merah dengan menggunakan operasi Morfologi, deteksi tepi Canny, dan transformasi Watershed. Data yang digunakan sebanyak 15 data citra dan setiap citra akan diuji dengan empat macam operasi Morfologi kemudian citra hasil Morfologi akan diuji sebanyak 16 kali percobaan dengan parameter masking, sigma, high threshold (HT), dan low threshold (LT) dari deteksi tepi Canny. Hasil pengujian kemudian disegmentasi dengan menggunakan transformasi Watershed. Perhitungan tingkat akurasi dilakukan dengan membandingkan koordinat tiap piksel citra hasil segmentasi dengan citra ground truth  dan menghasilkan nilai rata-rata akurasi sebesar 39.3 %.&#39;]}
2022-06-29 22:21:02 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/050411100558&gt; (referer: None)
2022-06-29 22:21:02 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/050411100558&gt;

{&#39;judul&#39;: [&#39;ANALISA DATA ANTARAN POS EXPRESS MENGGUNAKAN\r\nMETODE RADIAL BASIS FUNCTION NEURAL NETWORK (RBF-NN)\r\nSTUDY PT. POS INDONESIA SURABAYA&#39;], &#39;penulis&#39;: [&#39;Penulis : siti murtasiyah warda&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Bain Khusnul Khotimah.,S.T.,M.Kom&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Firli Irhamni, S.T., M.Kom.&#39;], &#39;abstrak&#39;: [&#39;PT. Pos Indonesia (Persero) merupakan salah satu perusahaan yang bergerak di bidang komunikasi. Saat ini,\r\nsalah produk pelayanan PT. Pos Indonesia (Persero) adalah produk Pos Express.  Produk  Pos  Express ini\r\ndiharapkan dapat diminati masyarakat dan dapat tetap bertahan bahkan  semakin menunjukkan keunggulan PT.\r\nPos Indonesia (Persero). Untuk  itu perlu dilakukan  analisis untuk melihat pola perkembangan, kemajuan  yang\r\ntelah ditunjukkan, bahkan untuk melihat dan memperoleh informasi, berupa peramalan  dalam waktu ke depan\r\nterhadap produk Pos Express yang masuk  ke kantor Mail  Processing Center  (MPC) Surabaya. Dalam  hal  ini\r\nanalisis yang dilakukan adalah peramalan jumlah produk Pos Express dengan menggunakan Metode RBF-NN\r\n(Radial Basic function neural  network).  Hasil  analisa  pada  ujicoba  yang  dilakukan  menghasilkan  nilai  yang\r\ncukup optimal, salah satunya pada percobaan 2 inputan dengan hasil peramalan pada epoch ke-60  yang\r\nmemperoleh hasil MSE : 0.124497 dan MAPE : 15.058923 dengan hasil ramal yang berjumlah 2587.9966.\r\nKata kunci: Peramalan , Jaringan Syaraf Tiruan (JST), Radial Basis Function neural network (RBF-NN).&#39;]}
2022-06-29 22:21:02 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100133&gt; (referer: None)
2022-06-29 22:21:02 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/080411100010&gt; (referer: None)
2022-06-29 22:21:02 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100007&gt; (referer: None)
2022-06-29 22:21:02 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100133&gt;

{&#39;judul&#39;: [&#39;Deteksi Manusia Menggunakan Histogram of Oriented Gradients dan Naïve Bayes Classifier&#39;], &#39;penulis&#39;: [&#39;Penulis : R.A. Uluwiyah Nur Oktavianis &#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Dr. Indah Agustien, S.Kom., M.Kom&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Ari Kusumaningsih, S.T, M.T&#39;], &#39;abstrak&#39;: [&#39;Deteksi manusia merupakan  suatu aplikasi yang berfungsi untuk mendeteksi objek manusia dalam sebuah citra. Beberapa keuntungan yang dapat diambil dari kajian ini, yaitu penerapan pada video pengawasan. Namun, dalam video pengawasan manusia yang dideteksi dalam keadaan bergerak. Sedangkan aplikasi ini, hanya mendeteksi atau menemukan objek manusia dari background sebuah citra. Sehingga dalam proses pembuatan aplikasi ini diperlukan perhitungan – perhitungan khusus untuk mendapatkan hasil yang baik. Penelitian ini menggunakan dua tahap yaitu proses ekstraksi fitur dan klasifikasi. Proses ekstraksi fitur menggunakan metode Histogram Of Oriented Gradients (HOG). Pada prinsipnya HOG menggunakan histogram untuk memperoleh ekstraksi fitur tersebut, dengan  beberapa langkah diantarnya yaitu konversi citra, gradient compute dan normalisasi. Sedangkan pada metode Naive Bayes Classifier ini di gunakan untuk proses pengklasifikasian atau pencocokan citra. Sehingga pada hasil akhir dapat diketahui kelas citra yang telah diuji. Berdasarkan uji coba aplikasi menggunakan perhitungan distribusi gaussian probabilitas pada naive bayes classfier dengan nilai threshold = 12,13,14 dan 15 pada skenario 1, 2 dan 3 diperoleh rata – rata akurasi sebesar 68,65%.\r\n\r\nKata kunci : Histogram Of Oriented Gradient, Naive Bayes Classifier\r\n&#39;]}
2022-06-29 22:21:02 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/080411100010&gt;

{&#39;judul&#39;: [&#39;KLASIFIKASI STATUS GIZI BALITA MENGGUNAKAN KOHONEN SELF ORGANIZING MAP\r\n&#39;], &#39;penulis&#39;: [&#39;Penulis : Uhty Zunairoh&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Bain Khusnul Khotimah, S.T., M.Kom.&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Aeri Rachmad, S.T., M.T.&#39;], &#39;abstrak&#39;: [&#39;Aplikasi klasifikasi status gizi balita ini dibuat untuk mempermudah dilakukannya kontrol terhadap perkembangan status gizi balita terutama di tempat penelitian ini dilakukan yaitu Kecamatan Arosbaya, tepatnya di Puskesmas Arosbaya. Aplikasi ini juga dapat digunakan sebagai media informasi karena dapat diisi dengan informasi yang berkaitan dengan Puskesmas Arosbaya sendiri. Untuk menentukan status gizi balita di aplikasi ini, digunakan metode Kohonen Self Organizing Map, dengan mengambil data dari Puskesmas Arosbaya. Parameter yang digunakan ada empat, yaitu: usia, jenis kelamin, tinggi badan, dan berat badan. Karena metode K-SOM hanya dapat digunakan untuk menentukan cluster maka dibuatlah sebuah rule untuk menentukan klasifikasi data pada kelas tertentu.Umumnya untuk mengetahui status gizi balita hanya menggunakan tiga parameter, namun pada penelitian ini akan menggunakan empat parameter. Hasil klasifikasi akan dibagi menjadi 3 kelas, yaitu: kelas 1 (status gizi kurang), kelas 2 (status gizi normal), dan kelas 3 (status gizi normal). Hasil penelitian menunjukkan bahwa sebanyak 88,17% (82 balita) balita berstatus gizi kurang, 8,6% (delapan balita) balita berstatus gizi normal, dan 3,23% (tiga balita) balita berstatus gizi lebih dengan nilai learning rate dan MSE akhir masing-masing 0,09436 dan 0,000792353. Sedangkan nilai akurasi, sencitivity, dan specificity masing adalah 100%.\r\n\r\nKata Kunci: Kohonen Self Organizing Map, status gizi balita, Puskesmas Arosbaya\r\n&#39;]}
2022-06-29 22:21:02 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100007&gt;

{&#39;judul&#39;: [&#39;Gerak Pekerja Pada Game Real Time Strategy Menggunakan Finite State Machine&#39;], &#39;penulis&#39;: [&#39;Penulis : Adi Chandra Laksono&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Kurniawan Eka P, S.Kom., Msc&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Arik Kurniawati, S.Kom., M.T.&#39;], &#39;abstrak&#39;: [&#39;Gerak pekerja ada pada game yang memiliki genre RTS (Real-Time Strategy). Gerak pekerja memiliki berbagai macam gerak. Oleh sebab itu dibutuhkan sebuah pendekatan konsep AI  untuk mendesain perilaku pekerja tersebut. Perilaku karakter tersebut harus ditambahi dengan AI (Artifical intelegent) agar perilakunya menjadi lebih hidup dan realistis.\r\nDalam penelitian ini AI yang digunakan adalah Finite State Machine. Finite State Machine digunakan untuk menentukan gerak pekerja terhadap parameter-parameter yang digunakan sebagai dasar gerak yang akan dilakukan . Selanjutnya akan disimulasikan pada game RTS dengan menggunakan game engine.\r\nHasil yang di peroleh dalam penelitian ini adalah penerapan metode Finite State machine untuk menentukan gerak pekerja berdasarkan parameter jumlah harta, prajurit, kondisi bangunan, dan stockpile (jumlah resources yang di bawa). \r\n\r\nKata kunci : Game, Real-Time Strategy, Gerak Pekerja, Finite State Machine.\r\n&#39;]}
2022-06-29 22:21:02 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100126&gt; (referer: None)
2022-06-29 22:21:02 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100092&gt; (referer: None)
2022-06-29 22:21:02 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/070411100109&gt; (referer: None)
2022-06-29 22:21:02 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://pta.trunojoyo.ac.id/welcome/detail/080411100083&gt; (referer: None)
2022-06-29 22:21:02 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100126&gt;

{&#39;judul&#39;: [&#39;RANCANG BANGUN GAME PERAWATAN SAPI KARAPAN MENGGUNAKAN METODE FUZZY LOGIC&#39;], &#39;penulis&#39;: [&#39;Penulis : NURRACHMAT&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Arik Kurniawati, S.Kom., M.T.&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Kurniawan Eka Permana, S.Kom., MSc.&#39;], &#39;abstrak&#39;: [&#39;Perkembangan game yang semakin pesat, memberikan berbagai alternative bagi peminatnya. Mulai dari bentuk game, cerita maupun media penyajian. Keberadaan game yang menggambarkan budaya Indonesia khususnya daerah kepulauan seperti Madura terhitung sedikit, sehingga dapat dirasa semakin lunturnya kebudayaan Indonesia bagi anak bangsa. Adanya peminat game yang semakin banyak dapat digunakan sebagai sarana pengenalan budaya asli Madura. Sebuah aplikasi game tentang olahraga yang sangat digemari di pulau Madura tersebut seperti Kerapan Sapi adalah sangatlah penting. Untuk itu perlu dibangun aplikasi game kerapan sapi sebagai upaya pelestarian budaya bangsa khususnya pulau Madura. Dengan upaya pembuatan game budaya maka dibangun  game perawatan sapi karapan menggunakan metode logika fuzzy (fuzzy logic), dengan menginputkan parameter kekuatan dan kesehatan sapi karapan untuk menentukan harga jual sapi karapan dalam sebuah game perawatan sapi karapan.\r\nKata kunci : game, kerapan sapi, perawatan sapi kerapan, budaya madura.&#39;]}
2022-06-29 22:21:02 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100092&gt;

{&#39;judul&#39;: [&#39;Perancangan Sistem Informasi Badan Kepegawaian Daerah ( BKD ) Bangkalan Sebagai Sub sistem dari E-Government Bangkalan Menggunakan TOGAF ADM &#39;], &#39;penulis&#39;: [&#39;Penulis : MALIKUL HAMZAH&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Moch. Kautsar Sophan, S.Kom., M.MT.&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Yeni Kustiyaningsih, S.Kom., M.Kom.&#39;], &#39;abstrak&#39;: [&#39;Kantor Badan Kepegawaian kota Bangkalan adalah instansi pemerintahan yang bergerak di bidang pelayanan kepegawaian. Untuk meningkatkan kualitas pelayanan maka perlu adanya sebuah sistem informasi yang mampu memonitoring dan membantu proses kinerja dari dinas tersebut. Oleh karena itu dalam penelitian  ini dibahas bagaimana menerapkan  Architecture Enterprise BKD Bangkalan dengan menggunakkan metode TOGAF ADM dan mengimplementa sikannya kedalam sebuah implementasi aplikasi Enterprise yang akan dibentuk menjadi satu keterpaduan dengan  E-government Bangkalan. TOGAF ADM memiliki empat komponen utama: arsitektur bisnis, arsitektur data, arsitektur teknologi dan arsitektur aplikasi. Intinya TOGAF digunakan untuk membuat Architecture Enterprise dari semua aspek tersebut. Dalam penelitian ini akan dibahas tentang perancangan sistem arsitektur Sistem informasi BKD Bangkalan sebagai sub-sistem dari E-government Bangkalan dengan menggunakan TOGAF ADM tujuannya agar dapat menghasilkan sistem aplikasi administrasi kantor Badan Kepegawaian Daerah  Bangkalan, membuat Blue Print, serta memperbaiki efisiensi, kenyamanan, serta aksesibilitas pelayanan terhadap publik agar  lebih baik. \r\n\r\nKata Kunci: Arsitektur interprise, TOGAF ADM, Arsitektur bisnis, Arsitektur data, Arsitektur aplikasi, Arsitektur teknologi\r\n&#39;]}
2022-06-29 22:21:03 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/070411100109&gt;

{&#39;judul&#39;: [&#39;EKSTRAKSI FITUR BERBASIS TWO DIMENSIONAL LINEAR DISCRIMINANT ANALYSIS  UNTUK PENGENALAN WAJAH&#39;], &#39;penulis&#39;: [&#39;Penulis : Muhammad Choirur Rozi&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Dr. Arif Muntasa, S.Si.,M.T&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Fitri Damayanti, S.Kom.,M.kom&#39;], &#39;abstrak&#39;: [&#39;Sistem pengenalan wajah adalah suatu sistem untuk mengenali identitas diri dari seseorang melalui wajah manusia. Teknologi ini mengidentifikasi bagian tubuh manusia yang unik dan tetap seperti wajah manusia. Hal khusus di bidang identifikasi dan pengenalan wajah manusia memanfaatkan pengolahan dan juga analisis citra wajah, yang akan berperan penting dalam proses pengenalan wajah manusia. Sistem ini dapat di manfaatkan dalam suatu sistem keamanan di bidang biometrika. Pada penelitian ini telah di bangun suatu perangkat lunak pengenalan citra wajah manusia menggunakan metode Two Dimensional Linear Discriminant Analysis (2DLDA) untuk menentukan karakteristik dari wajah manusia. Sedangkan pada tahap pengklasifikasian digunakan metode Angular Separation untuk mengukur kemiripan antara data pelatihan (training) dan data uji coba (testing). Melalui proses testing gambar wajah ini dapat di ketahui identitas diri dari seseorang. Dari uji coba aplikasi menggunakan klasifikasi Angular Separation di peroleh akurasi pengenalan benar sebesar  94.5%, pada  lima pose citra wajah pelatihan  dan lima pose citra wajah uji coba (testing) dengan jumlah data masing - masing dua ratus citra wajah manusia yang di ambil dari database ORL dengan menggunakan sepuluh eigen.\r\n\r\nKata kunci : Sistem pengenalan wajah, Two Dimensional Linear Discriminant Analysis, Angular Separation.\r\n&#39;]}
2022-06-29 22:21:03 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://pta.trunojoyo.ac.id/welcome/detail/080411100083&gt;

{&#39;judul&#39;: [&#39;IMPLEMENTASI  ALGORITMA PRIM  DAN DEPTH FIRST SEARCH PADA PEMBUATAN MAZE GAME BERBASIS ANDROID OS MOBILE&#39;], &#39;penulis&#39;: [&#39;Penulis : M Khoiril Anwar&#39;], &#39;pembimbing_1&#39;: [&#39;Dosen Pembimbing I : Cucun Very Angkoso, S.T., M.T.&#39;], &#39;pembimbing_2&#39;: [&#39;Dosen Pembimbing II :Arik Kurniawati S. Kom., M.T.&#39;], &#39;abstrak&#39;: [&#39;Teknologi mobile game beroperating system open source berkembang dengan sangat pesat. Karena keragaman variasinya, mobile game memiliki banyak peminat dari berbagai kalangan. Hal inilah yang menjadi dasar bagi para pengembang untuk terus mengembangkan mobile game. \r\nPada penelitian ini, sebuah mobile game untuk mengasah kemampuan berfikir telah dikembangkan dengan mengimplementasikan algoritma Prim dan Depth First Search. Dalam pembuatannya, algoritma Prim diterapkan pada saat pembuatan lintasan dari maze sedangkan algoritma Depth First Search diterapkan pada saat melakukan proses pencarian solusinya.\r\nDari hasil pengujian dapat disimpulkan bahwa algoritma Prim dan Depth First Search dapat berfungsi dengan baik pada resolusi screen 320 x 480 pixels dalam pembentukan lintasan dan pencarian solusi dari maze.\r\nKata kunci : Mobile Game, Android, Algoritma Prim, Algoritma Depth First Search.\r\n&#39;]}
2022-06-29 22:21:03 [scrapy.core.engine] INFO: Closing spider (finished)
2022-06-29 22:21:03 [scrapy.extensions.feedexport] INFO: Stored csv feed (40 items) in: detail.csv
2022-06-29 22:21:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{&#39;downloader/request_bytes&#39;: 19921,
 &#39;downloader/request_count&#39;: 41,
 &#39;downloader/request_method_count/GET&#39;: 41,
 &#39;downloader/response_bytes&#39;: 226794,
 &#39;downloader/response_count&#39;: 41,
 &#39;downloader/response_status_count/200&#39;: 41,
 &#39;elapsed_time_seconds&#39;: 7.186479,
 &#39;feedexport/success_count/FileFeedStorage&#39;: 1,
 &#39;finish_reason&#39;: &#39;finished&#39;,
 &#39;finish_time&#39;: datetime.datetime(2022, 6, 29, 15, 21, 3, 31511),
 &#39;httpcompression/response_bytes&#39;: 759371,
 &#39;httpcompression/response_count&#39;: 40,
 &#39;item_scraped_count&#39;: 40,
 &#39;log_count/DEBUG&#39;: 90,
 &#39;log_count/ERROR&#39;: 1,
 &#39;log_count/INFO&#39;: 11,
 &#39;response_received_count&#39;: 41,
 &#39;robotstxt/request_count&#39;: 1,
 &#39;robotstxt/response_count&#39;: 1,
 &#39;robotstxt/response_status_count/200&#39;: 1,
 &#39;scheduler/dequeued&#39;: 40,
 &#39;scheduler/dequeued/memory&#39;: 40,
 &#39;scheduler/enqueued&#39;: 40,
 &#39;scheduler/enqueued/memory&#39;: 40,
 &#39;start_time&#39;: datetime.datetime(2022, 6, 29, 15, 20, 55, 845032)}
2022-06-29 22:21:03 [scrapy.core.engine] INFO: Spider closed (finished)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="preprocessing-data">
<h1>Preprocessing Data<a class="headerlink" href="#preprocessing-data" title="Permalink to this headline">#</a></h1>
<section id="read-dataset">
<h2>Read Dataset<a class="headerlink" href="#read-dataset" title="Permalink to this headline">#</a></h2>
<p>Pada bagian ini digunakan untuk membaca dataset. Dataset akan dibaca dan diubah menjadi dataframe agar lebih mudah diolah. Hanya kolom abstrak yang diambil untuk diolah.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Membaca dataset dan hanya mengambil kolom</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;detail.csv&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;abstrak&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="cleaning-tokenizing">
<h2>Cleaning &amp; Tokenizing<a class="headerlink" href="#cleaning-tokenizing" title="Permalink to this headline">#</a></h2>
<p>Pada bagian ini digunakan untuk membersihkan dan melakukan tokenisasi data yang sudah dicrawling. Fungsi dari membersihkan data adalah membuang tanda baca dan membuatnya menjadi <em>lowercase</em>. Kemudian dilakukan tokenisasi untuk memecah kata.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Membersihkan dan melakukan tokenisasi data yang sudah dicrawling</span>
<span class="n">docs</span><span class="p">[</span><span class="s1">&#39;abstrak&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">docs</span><span class="p">[</span><span class="s1">&#39;abstrak&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[^a-zA-Z]&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">())))</span>
<span class="n">docs</span><span class="p">[</span><span class="s1">&#39;abstrak&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0      [sistem, informasi, akademik, siakad, merupaka...
1      [setiap, perusahaan, mengharapkan, adanya, hub...
2      [berjalannya, koneksi, jaringan, komputer, den...
3      [penggunaan, teknologi, mobile, saat, ini, san...
4      [penjadwalan, kuliah, di, perguruan, tinggi, m...
                             ...                        
117    [gerak, pekerja, ada, pada, game, yang, memili...
118    [perkembangan, game, yang, semakin, pesat, mem...
119    [kantor, badan, kepegawaian, kota, bangkalan, ...
120    [sistem, pengenalan, wajah, adalah, suatu, sis...
121    [teknologi, mobile, game, beroperating, system...
Name: abstrak, Length: 122, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="stopwords">
<h2>Stopwords<a class="headerlink" href="#stopwords" title="Permalink to this headline">#</a></h2>
<p>Pada bagian ini digunakan untuk menghapus kata-kata yang termasuk <em>stopword</em>. Kata-kata yang termasuk <em>stopword</em> tidak mengandung arti spesifik sehingga harus dihapus sebelum diolah. Di dalam proyek ini akan dilakukan penghapusan kata-kata bahasa indonesia dan inggris yang termasuk <em>stopword</em>.</p>
<section id="stopwords-dictionary">
<h3>Stopwords Dictionary<a class="headerlink" href="#stopwords-dictionary" title="Permalink to this headline">#</a></h3>
<p><a href="https://gist.github.com/sebleier/554280" title="NLTK's list of english stopwords">Kamus Stopword Bahasa Inggris</a></p>
<p><a href="https://github.com/stopwords-iso/stopwords-id/blob/master/raw/indonesian-stopwords-complete.txt" title="indonesian-stopwords-complete.txt">Kamus Stopword Bahasa Indonesia</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menghapus kata-kata bahasa indonesia dan inggris yang termasuk stopword</span>
<span class="n">stopwords_dictionary</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;indonesian&#39;</span><span class="p">)</span>
<span class="n">docs</span><span class="p">[</span><span class="s1">&#39;abstrak_no_sw&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">docs</span><span class="p">[</span><span class="s1">&#39;abstrak&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">doc</span><span class="p">:</span> <span class="p">[</span><span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">doc</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords_dictionary</span><span class="p">])</span>
<span class="n">docs</span><span class="p">[</span><span class="s1">&#39;abstrak_no_sw&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0      [sistem, informasi, akademik, siakad, sistem, ...
1      [perusahaan, mengharapkan, hubungan, pelanggan...
2      [berjalannya, koneksi, jaringan, komputer, lan...
3      [penggunaan, teknologi, mobile, marak, disampi...
4      [penjadwalan, kuliah, perguruan, kompleks, per...
                             ...                        
117    [gerak, pekerja, game, memiliki, genre, rts, r...
118    [perkembangan, game, pesat, alternative, pemin...
119    [kantor, badan, kepegawaian, kota, bangkalan, ...
120    [sistem, pengenalan, wajah, sistem, mengenali,...
121    [teknologi, mobile, game, beroperating, system...
Name: abstrak_no_sw, Length: 122, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="stemming">
<h2>Stemming<a class="headerlink" href="#stemming" title="Permalink to this headline">#</a></h2>
<p>Pada bagian ini digunakan untuk stemming. Stemming adalah sebuah metode yang digunakan untuk mengubah sebuah kata menjadi bentuk dasar dari kata tersebut, misalnya:</p>
<ul class="simple">
<li><p>Bekerja menjadi kerja</p></li>
<li><p>Memakan menjadi makan</p></li>
<li><p>Tulisan menjadi tulis</p></li>
</ul>
<section id="stemming-dictionary">
<h3>Stemming Dictionary<a class="headerlink" href="#stemming-dictionary" title="Permalink to this headline">#</a></h3>
<p><a href="https://github.com/har07/PySastrawi/blob/master/src/Sastrawi/Stemmer/data/kata-dasar.txt" title="kata-dasar.txt">Kamus Stemming Bahasa Indonesia</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mengubah sebuah kata menjadi bentuk dasar dari kata tersebut</span>
<span class="n">term_dict</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">factory</span> <span class="o">=</span> <span class="n">StemmerFactory</span><span class="p">()</span>
<span class="n">stemmer</span> <span class="o">=</span> <span class="n">factory</span><span class="o">.</span><span class="n">create_stemmer</span><span class="p">()</span>

<span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">[</span><span class="s1">&#39;abstrak_no_sw&#39;</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">term</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">term_dict</span><span class="p">:</span>
            <span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span>

<span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">term_dict</span><span class="p">:</span>
    <span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="o">=</span> <span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">term</span><span class="p">)</span>

<span class="n">docs</span><span class="p">[</span><span class="s1">&#39;abstrak_no_sw_stemmed&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">docs</span><span class="p">[</span><span class="s1">&#39;abstrak_no_sw&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">doc</span><span class="p">:</span> <span class="p">[</span><span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">])</span>
<span class="n">docs</span><span class="p">[</span><span class="s1">&#39;deskripsi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">docs</span><span class="p">[</span><span class="s1">&#39;abstrak_no_sw_stemmed&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">doc</span><span class="p">:</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">]))</span>
<span class="n">docs</span><span class="p">[</span><span class="s1">&#39;deskripsi&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="nn">Input In [12],</span> in <span class="ni">&lt;cell line: 11&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span>             <span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span> <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">term_dict</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">12</span>     <span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="o">=</span> <span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">term</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> <span class="n">docs</span><span class="p">[</span><span class="s1">&#39;abstrak_no_sw_stemmed&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">docs</span><span class="p">[</span><span class="s1">&#39;abstrak_no_sw&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
<span class="g g-Whitespace">     </span><span class="mi">15</span>     <span class="k">lambda</span> <span class="n">doc</span><span class="p">:</span> <span class="p">[</span><span class="n">term_dict</span><span class="p">[</span><span class="n">term</span><span class="p">]</span> <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">])</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span> <span class="n">docs</span><span class="p">[</span><span class="s1">&#39;deskripsi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">docs</span><span class="p">[</span><span class="s1">&#39;abstrak_no_sw_stemmed&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">doc</span><span class="p">:</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">]))</span>

<span class="nn">File C:\Python310\lib\site-packages\Sastrawi\Stemmer\CachedStemmer.py:20,</span> in <span class="ni">CachedStemmer.stem</span><span class="nt">(self, text)</span>
<span class="g g-Whitespace">     </span><span class="mi">18</span>     <span class="n">stems</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">))</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">20</span>     <span class="n">stem</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">delegatedStemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span>     <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">stem</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span>     <span class="n">stems</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stem</span><span class="p">)</span>

<span class="nn">File C:\Python310\lib\site-packages\Sastrawi\Stemmer\Stemmer.py:27,</span> in <span class="ni">Stemmer.stem</span><span class="nt">(self, text)</span>
<span class="g g-Whitespace">     </span><span class="mi">24</span> <span class="n">stems</span> <span class="o">=</span> <span class="p">[]</span>
<span class="g g-Whitespace">     </span><span class="mi">26</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">27</span>     <span class="n">stems</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stem_word</span><span class="p">(</span><span class="n">word</span><span class="p">))</span>
<span class="g g-Whitespace">     </span><span class="mi">29</span> <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">stems</span><span class="p">)</span>

<span class="nn">File C:\Python310\lib\site-packages\Sastrawi\Stemmer\Stemmer.py:36,</span> in <span class="ni">Stemmer.stem_word</span><span class="nt">(self, word)</span>
<span class="g g-Whitespace">     </span><span class="mi">34</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">stem_plural_word</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">35</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">36</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">stem_singular_word</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

<span class="nn">File C:\Python310\lib\site-packages\Sastrawi\Stemmer\Stemmer.py:84,</span> in <span class="ni">Stemmer.stem_singular_word</span><span class="nt">(self, word)</span>
<span class="g g-Whitespace">     </span><span class="mi">82</span> <span class="sd">&quot;&quot;&quot;Stem a singular word to its common stem form.&quot;&quot;&quot;</span>
<span class="g g-Whitespace">     </span><span class="mi">83</span> <span class="n">context</span> <span class="o">=</span> <span class="n">Context</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dictionary</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">visitor_provider</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">84</span> <span class="n">context</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">86</span> <span class="k">return</span> <span class="n">context</span><span class="o">.</span><span class="n">result</span>

<span class="nn">File C:\Python310\lib\site-packages\Sastrawi\Stemmer\Context\Context.py:37,</span> in <span class="ni">Context.execute</span><span class="nt">(self)</span>
<span class="g g-Whitespace">     </span><span class="mi">34</span> <span class="sd">&quot;&quot;&quot;Execute stemming process; the result can be retrieved with result&quot;&quot;&quot;</span>
<span class="g g-Whitespace">     </span><span class="mi">36</span> <span class="c1">#step 1 - 5</span>
<span class="ne">---&gt; </span><span class="mi">37</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_stemming_process</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">39</span> <span class="c1">#step 6</span>
<span class="g g-Whitespace">     </span><span class="mi">40</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dictionary</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_word</span><span class="p">):</span>

<span class="nn">File C:\Python310\lib\site-packages\Sastrawi\Stemmer\Context\Context.py:80,</span> in <span class="ni">Context.start_stemming_process</span><span class="nt">(self)</span>
<span class="g g-Whitespace">     </span><span class="mi">77</span>     <span class="k">return</span>
<span class="g g-Whitespace">     </span><span class="mi">79</span> <span class="c1">#step 4, 5</span>
<span class="ne">---&gt; </span><span class="mi">80</span> <span class="bp">self</span><span class="o">.</span><span class="n">remove_prefixes</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">81</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dictionary</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_word</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">82</span>     <span class="k">return</span>

<span class="nn">File C:\Python310\lib\site-packages\Sastrawi\Stemmer\Context\Context.py:89,</span> in <span class="ni">Context.remove_prefixes</span><span class="nt">(self)</span>
<span class="g g-Whitespace">     </span><span class="mi">87</span> <span class="k">def</span> <span class="nf">remove_prefixes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">88</span>     <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
<span class="ne">---&gt; </span><span class="mi">89</span>         <span class="bp">self</span><span class="o">.</span><span class="n">accept_prefix_visitors</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prefix_pisitors</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">90</span>         <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dictionary</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_word</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">91</span>             <span class="k">return</span>

<span class="nn">File C:\Python310\lib\site-packages\Sastrawi\Stemmer\Context\Context.py:111,</span> in <span class="ni">Context.accept_prefix_visitors</span><span class="nt">(self, visitors)</span>
<span class="g g-Whitespace">    </span><span class="mi">109</span> <span class="k">for</span> <span class="n">visitor</span> <span class="ow">in</span> <span class="n">visitors</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">110</span>     <span class="bp">self</span><span class="o">.</span><span class="n">accept</span><span class="p">(</span><span class="n">visitor</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">111</span>     <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dictionary</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_word</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">112</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_word</span>
<span class="g g-Whitespace">    </span><span class="mi">113</span>     <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_is_stopped</span><span class="p">:</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="term-frequency-inverse-document-frequency">
<h2>Term Frequency - Inverse Document Frequency<a class="headerlink" href="#term-frequency-inverse-document-frequency" title="Permalink to this headline">#</a></h2>
<p>Pada bagian ini digunakan untuk mengetahui nilai TF-IDF. TF-IDF adalah ukuran statistik yang menggambarkan pentingnya suatu term terhadap sebuah dokumen dalam sebuah korpus.</p>
<p>Rumus Term Frequency:</p>
<div class="math notranslate nohighlight">
\[
tf(t,d) = { f_{ t,d } \over \sum_{t' \in d } f_{t,d}}
\]</div>
<p><span class="math notranslate nohighlight">\( f_{ t,d } \quad\quad\quad\quad\quad\)</span>: Jumlah kata t muncul dalam dokumen</p>
<p><span class="math notranslate nohighlight">\( \sum_{t' \in d } f_{t,d} \quad\quad\)</span>: Jumlah seluruh kata yang ada dalam dokumen</p>
<p>Rumus Inverse Document Frequency:</p>
<div class="math notranslate nohighlight">
\[
idf( t,D ) = log { N \over { | \{ d \in D:t \in d \} | } }
\]</div>
<p><span class="math notranslate nohighlight">\( N \quad\quad\quad\quad\quad\quad\)</span> : Jumlah seluruh dokumen</p>
<p><span class="math notranslate nohighlight">\( | \{ d \in D:t \in d \} | \)</span> : Jumlah dokumen yang mengandung kata <span class="math notranslate nohighlight">\( t \)</span></p>
<p>Rumus Term Frequency - Inverse Document Frequency:</p>
<div class="math notranslate nohighlight">
\[
tfidf( t,d,D ) = tf( t,d ) \times idf( t,D )
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Proses Term Frequency - Inverse Document Frequency</span>
<span class="n">vect</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">()</span>
<span class="n">vect_text</span> <span class="o">=</span> <span class="n">vect</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">[</span><span class="s1">&#39;deskripsi&#39;</span><span class="p">])</span>
<span class="n">attr_count</span> <span class="o">=</span> <span class="n">vect</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Jumlah term dalam kumpulan dokumen : </span><span class="si">{</span><span class="n">attr_count</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah term dalam kumpulan dokumen : 1072
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menyimpan hasil TF-IDF ke dalam DataFrame</span>
<span class="n">tfidf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">vect_text</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span>
    <span class="n">columns</span><span class="o">=</span><span class="n">vect</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">tfidf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>abstract</th>
      <th>abstrak</th>
      <th>abu</th>
      <th>acu</th>
      <th>ada</th>
      <th>adm</th>
      <th>admin</th>
      <th>administrasi</th>
      <th>administrator</th>
      <th>adu</th>
      <th>...</th>
      <th>watershed</th>
      <th>web</th>
      <th>website</th>
      <th>wide</th>
      <th>wilayah</th>
      <th>window</th>
      <th>winnowing</th>
      <th>world</th>
      <th>www</th>
      <th>yogyakarta</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.306983</td>
      <td>0.051164</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1072 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menampilkan 5 kata paling sering muncul</span>
<span class="n">idf</span> <span class="o">=</span> <span class="n">vect</span><span class="o">.</span><span class="n">idf_</span>
<span class="n">dd</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">vect</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">(),</span> <span class="n">idf</span><span class="p">))</span>
<span class="n">l</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">dd</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">get</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;5 Kata paling sering muncul:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">l</span><span class="p">[:</span><span class="mi">5</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">. </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="se">\t</span><span class="s2">(Nilai idf: </span><span class="si">{</span><span class="n">dd</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5 Kata paling sering muncul:
1. hasil	(Nilai idf: 1.202026627873287)
2. kunci	(Nilai idf: 1.3291818033585336)
3. metode	(Nilai idf: 1.363667979429703)
4. sistem	(Nilai idf: 1.5148989491536264)
5. proses	(Nilai idf: 1.5565716455541945)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menampilkan 5 kata paling jarang muncul</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;5 Kata paling jarang muncul:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">l</span><span class="p">[:</span><span class="o">-</span><span class="mi">5</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">. </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="se">\t</span><span class="s2">(Nilai idf: </span><span class="si">{</span><span class="n">dd</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5 Kata paling jarang muncul:
1. yogyakarta	(Nilai idf: 4.308106958596143)
2. www	(Nilai idf: 4.308106958596143)
3. world	(Nilai idf: 4.308106958596143)
4. winnowing	(Nilai idf: 4.308106958596143)
</pre></div>
</div>
</div>
</div>
</section>
<section id="id1">
<h2>TOPIC MODELLING<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h2>
<section id="latent-semantic-analysis-lsa">
<h3>Latent Semantic Analysis(LSA)<a class="headerlink" href="#latent-semantic-analysis-lsa" title="Permalink to this headline">#</a></h3>
<p>Latent Semantic Analysis (LSA) merupakan sebuah metode yang memanfaatkan model statistik matematis untuk menganalisa struktur semantik suatu teks. LSA bisa digunakan untuk menilai abstrak tugas akhir dengan mengkonversikan abstrak tugas akhir menjadi matriks-matriks yang diberi nilai pada masing-masing term untuk dicari kesamaan dengan term. Secara umum, langkah-langkah LSA dalam penilaian abstrak tugas akhir adalah sebagai berikut:</p>
<ol class="simple">
<li><p>Text Processing</p></li>
<li><p>Document-Term Matrix</p></li>
<li><p>Singular Value Decomposition (SVD)</p></li>
<li><p>Cosine Similarity Measurement</p></li>
</ol>
<section id="singular-value-decomposition-svd">
<h4>Singular Value Decomposition(SVD)<a class="headerlink" href="#singular-value-decomposition-svd" title="Permalink to this headline">#</a></h4>
<p>Singular Value Decomposition (SVD) adalah sebuah teknik untuk mereduksi dimensi yang bermanfaat untuk memperkecil nilai kompleksitas dalam pemrosesan Document-Term Matrix. SVD merupakan teorema aljabar linier yang menyebutkan bahwa persegi panjang dari Document-Term Matrix dapat dipecah/didekomposisikan menjadi tiga matriks, yaitu Matriks ortogonal U, Matriks diagonal S, Transpose dari matriks ortogonal V.</p>
<div class="math notranslate nohighlight">
\[
A_{mn} = U_{mm} \times S_{mn} \times V^{T}_{nn}
\]</div>
<p><span class="math notranslate nohighlight">\( A_{mn} \)</span> : matriks awal</p>
<p><span class="math notranslate nohighlight">\( U_{mm} \)</span> : matriks ortogonal</p>
<p><span class="math notranslate nohighlight">\( S_{mn} \)</span> : matriks diagonal</p>
<p><span class="math notranslate nohighlight">\( V^{T}_{nn} \)</span> : Transpose matriks ortogonal V</p>
<p>Setiap baris dari matriks <span class="math notranslate nohighlight">\( U \)</span> (Document-Term Matrix) adalah bentuk vektor dari dokumen. Panjang dari vektor-vektor tersebut adalah jumlah topik. Sedangkan matriks <span class="math notranslate nohighlight">\( V \)</span> (Term-Topic Matrix) berisi kata-kata dari data.</p>
<p>SVD akan memberikan vektor untuk setiap dokumen dan kata dalam data. Kita dapat menggunakan vektor-vektor tersebut untuk mencari kata dan dokumen serupa menggunakan metode <strong>Cosine Similarity</strong>.</p>
<p>Dalam mengimplementasikan LSA, dapat menggunakan fungsi TruncatedSVD. parameter n_components digunakan untuk menentukan jumlah topik yang akan diekstrak.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Melakukan Latent Semantic Analysis</span>
<span class="n">lsa_model</span> <span class="o">=</span> <span class="n">TruncatedSVD</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;randomized&#39;</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">lsa_top</span><span class="o">=</span><span class="n">lsa_model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">vect_text</span><span class="p">)</span>
<span class="p">(</span><span class="n">count_doc_lsa</span><span class="p">,</span> <span class="n">count_topic_lsa</span><span class="p">)</span> <span class="o">=</span> <span class="n">lsa_top</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah dokumen</span><span class="se">\t</span><span class="s2">: </span><span class="si">{</span><span class="n">count_doc_lsa</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah topik</span><span class="se">\t</span><span class="s2">: </span><span class="si">{</span><span class="n">count_topic_lsa</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah dokumen	: 81
Jumlah topik	: 2
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Komposisi dokumen 0 berdasar topik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Document 0 :&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">topic</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lsa_top</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Topic </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> : </span><span class="si">{</span><span class="n">topic</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Document 0 :
Topic 0 : 23.36940181388153
Topic 1 : 13.856038617883309
</pre></div>
</div>
</div>
</div>
<p>Dari hasil diatas dapat kita simpulkan bahwa Topic 2 lebih dominan daripada topik 0 pada document 0</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menampilkan jumlah topik dan term</span>
<span class="p">(</span><span class="n">count_topic</span><span class="p">,</span> <span class="n">count_word</span><span class="p">)</span> <span class="o">=</span> <span class="n">lsa_model</span><span class="o">.</span><span class="n">components_</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah topik</span><span class="se">\t</span><span class="s2">: </span><span class="si">{</span><span class="n">count_topic</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah kata</span><span class="se">\t</span><span class="s2">: </span><span class="si">{</span><span class="n">count_word</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah topik	: 2
Jumlah kata	: 1072
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="term-penting-setiap-topik">
<h3>10 term penting setiap topik<a class="headerlink" href="#term-penting-setiap-topik" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Term paling penting untuk setiap topik</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">vect</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">comp</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lsa_model</span><span class="o">.</span><span class="n">components_</span><span class="p">):</span>
    <span class="n">vocab_comp</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="n">comp</span><span class="p">)</span>

    <span class="n">sorted_words</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">vocab_comp</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Topic </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: &quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span> <span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sorted_words</span> <span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Topic 0: 
citra sistem tulis hasil proses batik nilai metode data tangan

Topic 1: 
arsitektur enterprise togaf gizi bangkal pasien adm status informasi sistem
</pre></div>
</div>
</div>
</div>
</section>
<section id="latent-dirichlet-allocation-lda">
<h3>Latent Dirichlet Allocation (LDA)<a class="headerlink" href="#latent-dirichlet-allocation-lda" title="Permalink to this headline">#</a></h3>
<p><img alt="Model LDA" src="_images/dw-1.jpg" /></p>
<p><em>Latent Dirichlet Allocation (LDA)</em> adalah model generatif statistik yang dari koleksi data diskrit seperti kumpulan dokumen (<em>corpus</em>).</p>
<p><img alt="Konsep LDA" src="_images/dw-3.jpg" /></p>
<p>Awal dibuatnya LDA yaitu bahwa dokumen terdiri dari beberapa topik.  Proses mengasumsikan bahwa dokumen berasal dari topik tertentu melalui <em>imaginary random process</em>. Setiap topik dibentuk oleh distribusi kata-kata.</p>
<p><img alt="Konsep LDA" src="_images/dw-4.jpg" /></p>
<p>Topik yang mendeskripsikan kumpulan dari suatu dokumen dapat ditentukan setalah topik LDA dibuat. Pada sisi sebelah kanan gambar diatas menunjukkan daftar topik serta 15 kata dengan distribusi tertinggi untuk masing-masing topik tersebut.</p>
<p>Rumus Dirichlet Distribution:
$<span class="math notranslate nohighlight">\(
f\left(x_{1}, \ldots, x_{K} ; \alpha_{1}, \ldots, \alpha_{K}\right)=\frac{\Gamma\left(\sum_{i=1}^{K} \alpha_{i}\right)}{\prod_{i=1}^{K} \Gamma\left(\alpha_{i}\right)} \prod_{i=1}^{K} x_{i}^{\alpha_{i}-1}
\)</span>$</p>
<p>Untuk melakukan perhitungan LDA dengan library sklearn, dapat dilakukan dengan menggunakan kelas <em>LatentDirichletAllocation</em> yang ada pada modul <em>sklearn.decomposition</em>. Parameter yang digunakan antara lain:</p>
<ul class="simple">
<li><p>n_components = 2<br />
Mengatur jumlah topik menjadi 2</p></li>
<li><p>learning_method =’online’<br />
Mengatur agar metode pembelajaran secara online. sehingga akan lebih cepat ketika menggunakan data dalam jumlah besar.</p></li>
<li><p>random_state = 42<br />
Untuk mendapatkan hasil pengacakan yang sama selama 42 kali kode dijalankan</p></li>
<li><p>max_iter = 1 <br />
Untuk mengatur jumlah iterasi training data (epoch) menjadi 1 kali saja.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Melakukan Latent Dirichlet Allocation</span>
<span class="n">lda_model</span> <span class="o">=</span> <span class="n">LatentDirichletAllocation</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">learning_method</span><span class="o">=</span><span class="s1">&#39;online&#39;</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
<span class="n">lda_top</span> <span class="o">=</span> <span class="n">lda_model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">vect_text</span><span class="p">)</span>
<span class="p">(</span><span class="n">count_doc_lda</span><span class="p">,</span> <span class="n">count_topic_lda</span><span class="p">)</span> <span class="o">=</span> <span class="n">lda_top</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah dokumen</span><span class="se">\t</span><span class="s2">: </span><span class="si">{</span><span class="n">count_doc_lda</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah topik</span><span class="se">\t</span><span class="s2">: </span><span class="si">{</span><span class="n">count_topic_lda</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah dokumen	: 81
Jumlah topik	: 2
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Komposisi dokumen 0 berdasar topik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Document 0: &quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">topic</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lda_top</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Topic &quot;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="s2">&quot;: &quot;</span><span class="p">,</span><span class="n">topic</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="s2">&quot;%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Document 0: 
Topic  0 :  15.983404336048862 %
Topic  1 :  84.01659566395114 %
</pre></div>
</div>
</div>
</div>
<p>Dari hasil diatas dapat kita simpulkan bahwa Topic 1 lebih dominan daripada topik 0 pada document 0</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menampilkan jumlah topik dan term</span>
<span class="p">(</span><span class="n">count_topic_lda</span><span class="p">,</span> <span class="n">count_word_lda</span><span class="p">)</span> <span class="o">=</span> <span class="n">lda_model</span><span class="o">.</span><span class="n">components_</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah Topik</span><span class="se">\t</span><span class="s2">: </span><span class="si">{</span><span class="n">count_topic_lda</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah Term</span><span class="se">\t</span><span class="s2">: </span><span class="si">{</span><span class="n">count_word_lda</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah Topik	: 2
Jumlah Term	: 1072
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h3>10 term penting setiap topik<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mendapatkan term penting untuk setiap topik</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">vect</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">get_important_words</span><span class="p">(</span><span class="n">comp</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="n">vocab_comp</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="n">comp</span><span class="p">)</span>
    <span class="n">sorted_words</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">vocab_comp</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="n">n</span><span class="p">]</span>
    <span class="k">return</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">sorted_words</span><span class="p">])</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">comp</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lda_model</span><span class="o">.</span><span class="n">components_</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Topic &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;: &quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">get_important_words</span><span class="p">(</span><span class="n">comp</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Topic 0: 
citra hasil beroperating arsitektur dokumen supplier proses wajah data tentu

Topic 1: 
nilai lunak web gerak usaha pasien data gizi milik html
</pre></div>
</div>
</div>
</div>
</section>
<section id="term-penting-dengan-wordcloud">
<h3>50 term penting dengan wordcloud<a class="headerlink" href="#term-penting-dengan-wordcloud" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Membuat gambar word cloud setiap topik</span>
<span class="k">def</span> <span class="nf">draw_word_cloud</span><span class="p">(</span><span class="n">index</span><span class="p">):</span>
  <span class="n">imp_words_topic</span> <span class="o">=</span> <span class="n">get_important_words</span><span class="p">(</span><span class="n">lda_model</span><span class="o">.</span><span class="n">components_</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="mi">50</span><span class="p">)</span>
  
  <span class="n">wordcloud</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">imp_words_topic</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wordcloud</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menampilkan hasil word cloud topik 1</span>
<span class="n">draw_word_cloud</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/topic-modelling_44_0.png" src="_images/topic-modelling_44_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menampilkan hasil word cloud topik 2</span>
<span class="n">draw_word_cloud</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/topic-modelling_45_0.png" src="_images/topic-modelling_45_0.png" />
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Welcome to your Jupyter Book</p>
        </div>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Jupyter Book Community<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>